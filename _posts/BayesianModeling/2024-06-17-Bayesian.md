---
order: 1
title: What? Bayesian
date: 2024-06-17
categories: [Statistical Techs, Bayesian Modeling]
tags: [Statistics, Bayesian]
math: true
image:
  path: /_post_refer_img/BayesianModeling/Thumbnail.jpeg
---

## Compare Frequentist and Bayesian
-----

### 빈도주의자 vs. 베이지안

- **사건 $X$ 가 발생할 확률 $P(X)$ 의 정의**
    - **빈도주의자(Frequentist)** : 어떤 사건이 발생하는 장기적인 빈도

        $$
        P(X)
        $$

    - **베이지안(Bayesian)** : 어떤 사건이 발생할 것이라는 믿음 혹은 확신의 척도

        $$
        P(X \vert \theta)
        $$

- **모수 $\theta$ 의 이해**
    - **빈도주의자(Frequentist)** : 사건 발생 빈도에 대한 분포를 묘사하는 고정된 상수

        $$
        \theta=\mu, \sigma^2, p, \cdots
        $$

    - **베이지안(Bayesian)** : 사건 발생에 대한 믿음의 분포를 묘사하는 수로서, 확률적으로 변하는 수

        $$
        \theta \sim F
        $$

### 표본의 크기가 충분하다면

- 빈도주의자의 결론과 베이지안의 결론은 일치함

    $$
    \lim_{n \rightarrow \infty}{P(\theta \vert X_{1},X_{2},\cdots,X_{n})} \approx \mu, \sigma^2, p, \cdots
    $$

    - 사건 발생에 대한 믿음은 **신규 관측치에 의해 끊임없이 갱신되어** 사건 발생에 대한 장기적인 빈도로 수렴함

### 표본의 크기가 충분하지 않다면

> 표본의 크기는 결코 크지 않다. 만일 N이 충분한 추정을 얻기에 부족하다면 더 많은 데이터(또는 더 많은 가정)을 확보해야 한다. 그러나 일단 N이 충분히 크다면 데이터를 나눠 더 많은 것(가령 여론조사에서 전국적으로 훌륭한 추정을 얻었다면 남과 여, 지역별, 연령대별 그룹 등으로 나눠 추정할 수 있다)을 얻을 수 있다. N은 충분하지 않다. 만약 충분하더라도 여러분은 이미 더 많은 데이터가 필요한 다음 문제에 직면하기 때문이다. (Andrew Gelman)

- **빈도주의자(Frequentist)** : 모수(미지의 상수)에 대한 신뢰구간을 확대함으로써 **모수 추정 과정 상의 불확실성을 최소화함**

    $$
    \text{CI}_{\theta}=\bar{X}\pm Z\cdot\frac{\sigma}{\sqrt{n}}
    $$

    - $\text{CI}_{\theta}$ : 모수 $\theta$ 에 대한 신뢰구간
    - $\bar{X}$ : 표본 평균
    - $Z$ : 신뢰수준에 해당하는 Z-value
    - $\sigma$ : 모표준편차
    - $n$ : 표본의 크기

- **베이지안(Bayesian)** : 모수(확률변수)에 대한 사전확률을 도입함으로써 **모수 자체의 불확실성을 모형화함**

    $$
    P(\theta \vert X)=\frac{P(X \vert \theta)\cdot P(\theta)}{P(X)}
    $$

    - $P(\theta)$ : 모수 $\theta$ 에 대한 **사전확률(Prior Probability)**
    - $P(\theta \vert X)$ : 관측치 $X$ 가 주어졌을 때 모수 $\theta$ 에 대한 **사후확률(Posterior Probability)**
    - $P(X \vert \theta)$ : 모수 $\theta$ 가 주어졌을 때 관측치 $X$ 가 발생할 가능성으로서 **우도(Likelihood)**
    - $P(X)$ : 관측치 $X$ 의 주변확률

        $$
        P(X)=\begin{cases}\begin{aligned}
        \int{P(X \vert \theta)P(\theta)\text{d}\theta},\;&\text{where X is continuous}\\
        \sum_{\theta}{P(X \vert \theta)P(\theta)},\;&\text{where X is discrete}
        \end{aligned}\end{cases}
        $$

## Bayesian Framework
-----

### 베이즈 정리

- **베이즈 정리(Bayes' Theorem)**

    > 사상 $A_{1},A_{2},\cdots,A_{n}$ 이 표본공간 $S$ 의 분할이고, $P(A_{i})>0,P(X)>0$ 이면 $X$ 에 대한 $A_{k}$ 의 조건부 확률은 다음과 같음

    $$\begin{aligned}
    P(A_{k} \vert X)
    &=\frac{P(A_{k} \cap X)}{P(X)}\\
    &=\frac{P(A_{k})\cdot P(X \vert A_{k})}{P(X)}\\
    &=\frac{P(A_{k})\cdot P(X \vert A_{k})}{\sum_{i=1}^{n}{P(A_{i}) \cdot P(X \vert A_{i})}} \propto P(A_{k})\cdot P(X \vert A_{k})
    \end{aligned}$$

    - $P(A_{k})$ : $A_{k}$ 의 사전확률
    - $P(A_{k} \vert X)$ : $X$ 가 주어졌을 때 $A_{k}$ 의 사후확률
    - $P(X \vert A_{k})$ : $A_{k}$ 가 주어졌을 때 $X$ 의 우도
    - $P(X)$ : $X$ 의 주변확률

- **확률밀도함수(혹은 확률질량함수)로 표현한 베이즈 정리**

    $$
    P(\theta \vert X)=\frac{\pi(\theta)\cdot P(X \vert \theta)}{P(X)} \propto \pi(\theta)\cdot P(X \vert \theta)
    $$

    - $\theta$ : 모수
    - $X$ : 관측된 데이터
    - $\pi(\theta)$ : $\theta$ 의 사전분포
    - $P(\theta \vert X)$ : $\theta$ 의 사후분포
    - $P(X \vert \theta)$ : $\theta$ 에 대한 $X$ 의 우도함수
    - $P(X)$ : $X$ 의 주변확률

### 베이지안의 최적 모수 탐색 방법

- **사전확률(Prior Probability)** : 사건 발생 전, 가지고 있는 정보를 기초로 하여 설정된 초기 믿음
    - 사전에 공정한 동전이라는 정보가 주어졌다고 하자
    - 앞면이 나올 확률 $\theta$ 에 대한 사전확률분포

        $$
        P(\theta)=\frac{1}{2}
        $$

- **사후확률(Posterior Probability)** : 사건 발생 후, 추가된 정보를 고려하여 갱신된 믿음
    - 동전이 앞으로 떨어지는 것을 관측했다고 하자
    - 추가된 정보($X$)를 고려하여 갱신된 앞면이 나올 확률 $\theta \vert X$ 에 대한 사후확률분포

        $$
        P(\theta \vert X)= 1
        $$

- **최대우도추정법(Maximum Likelihood Estimation, MLE)** : 관측치가 주어졌을 때, 해당 관측치가 발생할 가능성이 가장 높은 모수(parameter)의 값을 찾는 방법
    - **우도(Likelihood)** : 모수의 특정 값이 주어졌을 때, 관측치가 실제로 발생할 가능성
    - **우도함수(Likelihood Function)** : 모수 $\theta$ 에 관한 관측치가 실제로 발생할 가능성의 함수

        $$\begin{aligned}
        \mathcal{L}(\theta)
        &=P(X \vert \theta)\\
        &=\prod_{i=1}^{n}{f(x_{i} \vert \theta)}
        \end{aligned}$$

        - $f(X_{i} \vert \theta)$ : 모수가 $\theta$ 로 주어졌을 때 관측치 $X_{i}$ 에 대한 확률밀도함수 혹은 확률질량함수

    - **최우추정량(Maximum Likelihood Estimator; MLE)** : 우도를 최대화하는 모수

        $$
        \hat{\theta}=\text{arg}\max_{\theta}{\mathcal{L}(\theta)}
        $$

### `[example]` 동전 던지기

> 동전을 던졌을 때 앞면이 나올 확률을 $\theta$ 라고 하자. $\theta$ 에 대한 정보가 아무것도 없다고 가정하자. 즉, $\theta$ 는 0과 1 사이의 무작위수일 것이라고 믿어지고 있다. 동전을 두 번 던졌는데 두 번 다 앞면이 나왔다. 그렇다면 $\theta$ 에 대한 믿음은 어떻게 변화할까?

![01](/_post_refer_img/BayesianModeling/01-01.png){: width="100%"}

- **문제에서 주어진 정보**

    $$\begin{aligned}
    \theta &\sim \text{Uniform}(0,1)\\
    X \vert \theta &\sim \text{Bin}(n,\theta)
    \end{aligned}$$

- **목적 함수 정의**

    $$
    P(\theta \vert X)=\frac{\pi(\theta)P(X \vert \theta)}{P(X)} \propto \pi(\theta)P(X \vert \theta)
    $$

    - $\pi(\theta)$ : $\theta$ 에 대한 사전확률

        $$
        \pi(\theta)=1 \quad \because \theta \sim \text{Uniform}(0,1)
        $$

    - $P(X \vert \theta)$ : $\theta$ 에 대한 $X$ 의 우도함수 혹은 확률질량함수

        $$
        P(X \vert \theta)=\frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X} \quad \because X \vert \theta \sim \text{Bin}(n,\theta)
        $$

    - $P(X)$ : $X$ 의 주변확률로서 정규화 상수($\theta$ 에 대한 함수가 아니므로 이후 생략)

        $$\begin{aligned}
        P(X)
        &= \int_{0}^{1}{\frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X}}\text{d}\theta\\
        &= \frac{n!}{X!(n-X)!} \cdot \int_{0}^{1}{\theta^{X} \cdot (1-\theta)^{n-X}}\text{d}\theta\\
        &= \frac{n!}{X!(n-X)!} \cdot \text{B}(X+1,n-X+1)\\
        &= \frac{n!}{X!(n-X)!} \cdot \frac{\Gamma(X+1)\Gamma(n-X+1)}{\Gamma(n+2)} \quad \because (X+1),(n-X+1) \in \mathbf{R}^{+}\\
        &= \frac{n!}{X!(n-X)!} \cdot \frac{X!(n-X)!}{(n+1)!} \quad \because (X+1),(n-X+1) \in \mathbf{Z}^{+}\\
        &= \frac{1}{n+1}
        \end{aligned}$$

        - $\text{B}(\alpha,\beta)$ : 베타함수

            $$\begin{aligned}
            \text{B}(\alpha,\beta)
            &= \int_{0}^{1}{t^{\alpha-1}(1-t)^{\beta-1}}\text{d}t\\
            &= \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)} \quad \text{where}\; \alpha,\beta \in \mathbf{R}^{+}
            \end{aligned}$$

        - $\Gamma(n)$ : 감마함수

            $$\begin{aligned}
            \Gamma(n)
            &= \int_{0}^{\infty}{t^{(n-1)}e^{-t}}\text{d}t\\
            &= (n-1)! \quad \text{where}\; n \in \mathbf{Z}^{+}
            \end{aligned}$$

- **결론** : $\theta$ 의 사후확률은 베타분포 $\text{Beta}(3,1)$ 을 따름

    $$\begin{aligned}
    P(\theta \vert X)
    &\propto \pi(\theta)P(X \vert \theta)\\
    &= \frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X}\\
    \\
    \therefore P(\theta \vert X)
    &\sim \text{Beta}(X+1,n-X+1)
    \end{aligned}$$

    - $\text{Beta}(\alpha,\beta)$ : 베타분포

        $$
        f(x)
        = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{\text{B}(\alpha,\beta)}
        \sim \text{Beta}(\alpha,\beta)
        $$