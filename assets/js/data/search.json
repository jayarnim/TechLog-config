[
  
  {
    "title": "Hierarchical Clustering",
    "url": "/posts/Hierarchical_Clustering/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Clustering",
    "date": "2024-01-16 00:00:00 +0900",
    





    
    "snippet": "What? Hierarchical ClusteringHierarchical Clustering      정의 : 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram) : 결합 혹은 분할하는 순서를 나타내는 계층적...",
    "content": "What? Hierarchical ClusteringHierarchical Clustering      정의 : 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram) : 결합 혹은 분할하는 순서를 나타내는 계층적 트리모형            종류              상향식 군집화(Agglomerative Clustering) : 개별 개체들을 유사한 개체/군집과 계층적으로 통합해가는 방식      하향식 군집화(Divisive Clustering) : 표본을 유의미하게 구분되는 지점마다 계층적으로 분할해가는 방식      How to Agglomerative Clustering      모든 개체를 개별 군집으로서 정의함\\[C_{i} = \\{\\overrightarrow{x}_{i}\\} \\quad \\text{for} \\quad i=1,2,\\cdots, n\\]        군집 간 거리 행렬을 계산함\\[\\mathbf{D}_{i,j}=d(C_{i},C_{j})\\]        가장 가까운 두 개의 군집을 하나의 군집으로 통합함\\[\\begin{aligned} C_{k}&amp;=\\hat{C}_{i} \\cup \\hat{C}_{j}\\\\ \\hat{C}_{i},\\hat{C}_{j}&amp;=\\argmin_{C_{i},C_{j}}{d(C_{i},C_{j})} \\end{aligned}\\]        군집 간 거리 행렬을 갱신함\\[\\mathbf{D}_{N} = \\mathbf{D}_{N-1} \\quad \\text{Recalculate} \\quad d(C_{i^{\\forall} \\ne k},C_{k})\\]        모든 개체가 하나의 군집으로 통합될 때까지 ③, ④의 과정을 반복함  How to Calculate Distance      Single Linkage(Minimum Distance) : 각 군집에 속한 개체들 사이 거리 최소값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\min_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Complete Linkage(Maximum Distance) : 각 군집에 속한 개체들 사이 거리 최대값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\max_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Average Linkage(Mean Distance) : 각 군집에 속한 개체들 사이 거리 평균\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{a} \\in \\mathbf{A}}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Centroid Linkage(Distance Between Centroids) : 각 군집 중심 간 거리\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= d(\\overrightarrow{\\mu}_{A},\\overrightarrow{\\mu}_{B})\\\\  \\overrightarrow{\\mu}_{A}  &amp;= \\frac{1}{|\\mathbf{A}|}\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{\\overrightarrow{a}}\\\\  \\overrightarrow{\\mu}_{B}  &amp;= \\frac{1}{|\\mathbf{B}|}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{\\overrightarrow{b}}  \\end{aligned}\\]        Ward’s Method : 병합 후 SSE와 병합 전 개별 군집의 SSE의 합의 차\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{c} \\in \\mathbf{C}}{d(\\overrightarrow{c},\\overrightarrow{\\mu}_{C})} - \\Big[\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{d(\\overrightarrow{a},\\overrightarrow{\\mu}_{A})} + \\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{b},\\overrightarrow{\\mu}_{B})}\\Big]\\\\  \\mathbf{C}  &amp;= \\mathbf{A} \\cup \\mathbf{B}  \\end{aligned}\\]  sklearn.cluster.AgglomerativeClusteringfrom sklearn.cluster import AgglomerativeClustering      n_clusters(default : 2) : 생성할 클러스터의 수        distance_threshold(default : None) : 병합하기 위한 클러스터 간 거리 임계값    linkage(default : 'ward'): 클러스터 간 거리 계산 방식          'ward'      'complete'      'average'      'single'        affinity(default : 'euclidean'): 관측치 간 거리 계산 방식          'manhattan' or 'l1'      'euclidean' or 'l2'      'cosine'      'precomputed'        memory(default : None) : 계산된 거리 행렬을 저장할 위치이미지 출처  https://towardsdatascience.com/hierarchical-clustering-explained-e59b13846da8  https://harshsharma1091996.medium.com/hierarchical-clustering-996745fe656b"
  },
  
  {
    "title": "DBSCAN",
    "url": "/posts/DBSCAN/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Clustering",
    "date": "2024-01-15 00:00:00 +0900",
    





    
    "snippet": "Density-Based Spatial Clustering of Applications with Noise      정의 : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empt...",
    "content": "Density-Based Spatial Clustering of Applications with Noise      정의 : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empty Subset                      Maximality                  표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 에 대하여,&lt;/br&gt; $\\overrightarrow{p} \\in C \\subseteq D$ 이고, $\\overrightarrow{q}$ 가 $\\overrightarrow{p}$ 로부터 밀도 기준 도달 가능한(Directly Density-Reachable) 벡터이면&lt;/br&gt; $\\overrightarrow{q} \\in C$ 임                            Connectivity                  군집 $C$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 간에는 밀도 기준 연결되어 있음(Density-Connected)                    용어의 이해      $\\varepsilon$-neighborhood of a point              표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}$ 에 대하여,&lt;/br&gt;$\\overrightarrow{p}$ 의 이웃 집합 $N_{\\varepsilon}(\\overrightarrow{p})$ 은 $\\overrightarrow{p}$ 와의 거리가 $\\varepsilon$ 이하인 관측치 벡터 $\\overrightarrow{q}$ 의 집합임    \\[N_{\\varepsilon}(\\overrightarrow{p})  =\\{\\overrightarrow{q} \\in D \\big| d(\\overrightarrow{p},\\overrightarrow{q}) \\le \\varepsilon\\}\\]        Directly Density-Reachable              Core Point Condition 을 만족하는 관측치 벡터 $\\overrightarrow{p} \\in D$ 에 대하여,&lt;/br&gt;그 이웃 관측치 벡터($\\varepsilon$-neighborhood of a point) $\\overrightarrow{q}$ 는 $\\overrightarrow{p}$ 로부터 밀도 기준 직접 도달 가능한(Directly Density-Reachable) 관측치 벡터임                      Core Point Condition\\[|N_{\\varepsilon}(\\overrightarrow{p})| \\ge \\text{MinPts}\\]                    Reachability\\[\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{p})\\]                  Density-Reachable              Core Point Condition 을 만족하는 관측치 벡터 $\\overrightarrow{p} \\in D$ 에 대하여,&lt;/br&gt; $\\overrightarrow{p}$ 와 $\\overrightarrow{q}$ 사이에 $\\overrightarrow{p}$ 로부터 밀도 기준 직접 도달 가능한 관측치 벡터 $\\overrightarrow{x}{1},\\overrightarrow{x}{2},\\cdots,\\overrightarrow{x}_{n}$ 이 연쇄적으로 존재한다면,&lt;/br&gt; $\\overrightarrow{q}$ 는 $\\overrightarrow{p}$ 로부터 밀도 기준 도달 가능한(Density-Reachable) 관측치 벡터임                                                          $              N_{\\varepsilon}(\\overrightarrow{p})              \\ge \\text{MinPts}$                                          $\\overrightarrow{x}{1} \\in N{\\varepsilon}(\\overrightarrow{p})$                                                  $              N_{\\varepsilon}(\\overrightarrow{x}_{\\forall})              \\ge \\text{MinPts}$                                          $\\overrightarrow{x}{i+1} \\in N{\\varepsilon}(\\overrightarrow{x}_{i})$      $\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{x}_{n})$            Density-Connected              Core Point Condition 을 만족하는 관측치 벡터 $\\overrightarrow{p},\\overrightarrow{q} \\in D$ 에 대하여,&lt;/br&gt; $\\overrightarrow{p}$ 로부터 밀도 기준 도달 가능한(Density-Connected) 동시에 $\\overrightarrow{q}$ 로부터 밀도 기준 도달 가능한(Density-Connected) 관측치 벡터 $\\overrightarrow{x} \\in D$ 가 적어도 하나 존재한다면,&lt;/br&gt; $\\overrightarrow{p},\\overrightarrow{q}$ 는 밀도 기준 연결되어 있음(Density-Connected)                                                          $              N_{\\varepsilon}(\\overrightarrow{p})              \\ge \\text{MinPts}$                                          $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{p})$                                                  $              N_{\\varepsilon}(\\overrightarrow{q})              \\ge \\text{MinPts}$                                          $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{q})$      sklearn.cluster.DBSCANfrom sklearn.cluster import DBSCANGeneral HyperParameter  random_state(default : None)  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter      eps(default : 0.5) : 직경    metric(default : 'euclidean') : 직경 측정 방법          'l1', 'manhattan' or 'cityblock' : 맨해튼 거리 측정법      'l2' or 'euclidean' : 유클리드 거리 측정법      'cosine' : 코사인 거리 측정법      'haversine' : 하버사인 거리 측정법      callable        p(default : None) : metric 의 아규먼트가 'minkowski' 인 경우 추가 설정          1 : 맨해튼 거리 측정법      2 : 유클리드 거리 측정법        min_samples(default : 5) : 최소 요소 갯수Atrribute  labels_ : 각 관측치가 속한 군집 번호          -1 : 이상치 군집        core_sample_indices_ : 군집별 핵심 요소의 행 번호이미지 출처  https://ai.plainenglish.io/dbscan-density-based-clustering-aaebd76e2c8c  https://journals.sagepub.com/doi/10.1177/1748301817735665"
  },
  
  {
    "title": "k-Means",
    "url": "/posts/kMeans/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Clustering",
    "date": "2024-01-14 00:00:00 +0900",
    





    
    "snippet": "What? k-Meansk-Means      정의 : 중심점 기반 배타적 분리형 군집화 알고리즘            목표 : 각 군집에 대하여, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화함\\[\\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j}...",
    "content": "What? k-Meansk-Means      정의 : 중심점 기반 배타적 분리형 군집화 알고리즘            목표 : 각 군집에 대하여, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화함\\[\\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j} \\in C_{i}}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}}\\]  한계점      초기 군집 중심에 민감함            이상치에 민감함            구형이 아닌 형태의 군집을 탐지하기 어려움            서로 다른 규모의 군집을 탐지하기 어려움            서로 다른 밀도의 군집을 탐지하기 어려움      중심점 탐색 과정      군집 갯수를 설정함\\[X=C_{1} \\cup C_{2} \\cup \\cdots \\cup C_{k}\\\\ \\\\ C_{i} \\cap C_{j \\ne i} = \\emptyset\\]        $k$ 개의 초기 군집 중심 벡터 $\\overrightarrow{c}$ 를 임의로 선정함\\[M=\\{\\overrightarrow{\\mu}_{1},\\overrightarrow{\\mu}_{2},\\cdots,\\overrightarrow{\\mu}_{k}\\}\\]        모든 관측치 벡터 $\\overrightarrow{x}$ 를 가장 가까운 거리에 위치한 중심 벡터 $\\overrightarrow{\\mu}$ 의 군집에 배타적으로 할당함\\[\\overrightarrow{x}_{j} \\rightarrow C_{i}\\\\ \\begin{aligned} \\\\\\text{s.t.} \\quad  &amp; i=\\argmin_{i}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}\\\\ &amp;\\overrightarrow{\\mu}_{i} \\in C_{i} \\end{aligned}\\]        각 군집별 할당된 관측치 벡터들의 평균 벡터로 군집 중심 벡터를 갱신함\\[\\begin{aligned} \\overrightarrow{\\mu}_{i} &amp;=\\displaystyle\\frac{1}{|C_{i}|}\\sum_{\\overrightarrow{x}_{j}\\in C_{i}}{\\overrightarrow{x}_{j}} \\end{aligned}\\]        ③, ④의 과정을 반복하여 최적의 군집 중심 벡터 집합 $\\hat{M}$ 을 탐색함\\[\\begin{aligned} \\hat{M} &amp;= \\{\\overrightarrow{\\mu}_{i} \\big| \\argmin_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j} \\in C_{i}}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}}\\} \\end{aligned}\\]  sklearn.cluster.KMeansfrom sklearn.cluster import KMeansGeneral HyperParameter  random_state(default : None)Model HyperParameter      n_cluster(default : 8) : 군집 갯수    init(default : 'k-means++') : 중심점 초기화 방법          'k-means++'      'random'      callable        n_init(default : 10) : 중심점 초기화 횟수          'auto'      int            max_iter(default : 300) : 학습(Means 최소화) 최대 횟수    tol(default : 1e-4) : 허용 손실Attribute  labels_ : 각 관측치가 속한 군집 번호  cluster_centers_ : 군집별 중심점 위치  n_iter_ : 중심점 이동 횟수  inertia_ : 군집별 Means 평균으로서 수치가 낮을수록 응집도가 높다고 판단함이미지 출처  https://ai-times.tistory.com/158  https://github.com/pilsung-kang/multivariate-data-analysis/blob/master/09%20Clustering/09-2_K-Means%20Clustering.pdf  https://github.com/lovit/python_ml_intro/blob/master/lecture_notes/10_clustering.pdf  https://paulvanderlaken.com/2018/12/12/visualizing-the-inner-workings-of-the-k-means-clustering-algorithm/"
  },
  
  {
    "title": "What? Clustering",
    "url": "/posts/Clustering/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Clustering, Metric",
    "date": "2024-01-13 00:00:00 +0900",
    





    
    "snippet": "What? Cluster AnalysisCluster Analysis      정의 : 표본을 관측치 간 유사성과 상이성을 계산하여 k개의 군집으로 분할하는 작업          Cluster analysis or clustering is the task of grouping a set of objects in such a way that object...",
    "content": "What? Cluster AnalysisCluster Analysis      정의 : 표본을 관측치 간 유사성과 상이성을 계산하여 k개의 군집으로 분할하는 작업          Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. (by.Wikipedia)            목표 : 군집 내 응집도 최대화 및 군집 간 분리도 최대화            판별 분석과 비교              판별 분석(Classification Analysis)                  학습 방식 : 지도학습(훈련 관측치의 정답 정보를 사전에 알고 있음)          학습 목표 : $X$ 와 $Y$ 의 관계를 나타내는 함수를 탐색함                    군집 분석(Cluster Analysis)                  학습 방식 : 비지도학습(훈련 관측치의 정답 정보를 사전에 알 수 없거나 존재하지 않음)          학습 목표 : 주어진 표본을 분할하는 여러 개의 군집을 탐색함                    구분      관측치 중복 여부에 따른 구분              Hard(or Crisp) Clustering : 관측치가 하나의 군집에만 할당됨      Soft(or Fuzzy) Clustering : 관측치가 여러 개의 군집에 할당될 수 있음            군집 간 위계 여부에 따른 구분              Partitional Clustering : 군집 간 위계가 존재하지 않음      Hierarchical Clustering : 군집 간 위계가 존재함      Metrics군집화 유효성 평가 기준  External : 정답 정보와의 비교          Rand Statistic      Jaccard Coefficient      Folks and Mallows Index      Hurbert $\\Gamma$ Statistic      V-Measure        Internal : 군집 내 응집도          Cophenetic Correlation Coefficient      Sum of Squared Error(SSE)      Cohesion and Separation        Relative : 군집 간 분리도          Dunn Family of Indices      Davies-Bouldin Index      Semi-partial R-squared      SD Validity Index      Silhouette      External Metrics      V-Measure : 정확성과 완전성의 조화평균\\[\\begin{aligned}  \\text{V}  &amp;= 2\\times\\frac{H(C|K) \\cdot C(K|C)}{H(C|K) + C(K|C)}  \\end{aligned}\\]                                                      $H(C              K)$ : 정확성(Homogeneity)                                                                                      $C(K              C)$ : 완전성(Completeness)                                                정확성(Homogeneity) : 각 군집의 클래스에 대한 엔트로피 합계\\[\\begin{aligned}  H(C|K)  &amp;= -\\sum_{k=1}^{K}{\\sum_{c=1}^{C}{P(c|k) \\cdot \\log{P(c|k)}}}  \\end{aligned}\\]          $k$ : 군집 번호      $c$ : 클래스 번호                                                  $P(c              k)$ : 군집 $K=k$ 가 주어졌을 때, 클래스 $C=c$ 가 발생할 가능성                                                완전성(Completeness) : 각 클래스의 군집에 대한 엔트로피 합계\\[\\begin{aligned}  C(K|C)  &amp;= -\\sum_{c=1}^{C}{\\sum_{k=1}^{K}{P(k|c) \\cdot \\log{P(k|c)}}}  \\end{aligned}\\]                                                      $P(k              c)$ : 클래스 $C=c$ 가 주어졌을 때, 군집 $K=k$ 가 발생할 가능성                                          Internal Metrics      Sum of Squared Error(SSE) : 각 군집의 중심점 벡터와 해당 군집 내 관측치 벡터 간 거리 자승으로 측정한 군집 응집도\\[\\begin{aligned}  \\text{SSE}  &amp;= \\sum_{k=1}^{K}{\\sum_{\\overrightarrow{x}_{i} \\in C_{k}}{||\\overrightarrow{x}_{i}-\\overrightarrow{\\mu}_{k}||^2}}  \\end{aligned}\\]          $k$ : 군집 번호      $C_{k}$ : $k$ 번째 군집      $\\overrightarrow{x}{i} \\in C{k}$ : 군집 $C_{k}$ 의 $i$ 번째 관측치 벡터      $\\overrightarrow{\\mu}{k} \\in C{k}$ : 군집 $C_{k}$ 의 중심 벡터      Relative Metrics      Dunn Index : 군집 내 응집도(Cohesion) 최대값 대비 군집 간 분리도(Separation) 최소값 비율\\[\\begin{aligned}  \\text{DI}  &amp;= \\frac{\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}}{\\max_{1 \\le k \\le K}{\\Delta(C_{k})}}  \\end{aligned}\\]          $\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}$ : 군집 간 분리도 최소값으로서 분리도에 대한 최악의 경우      $\\max_{1 \\le k \\le K}{\\Delta(C_{k})}$ : 군집 내 응집도 최대값으로서 응집도에 대한 최악의 경우            실루엣 계수(Silhouette) : 군집 내 응집성(cohesion)과 군집 간 분리도(separation)를 종합적으로 고려하여 측정한 개별 관측치 벡터에 대한 군집화 적합성의 평균값\\[\\begin{aligned}  \\text{S}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\frac{b(\\overrightarrow{x}_{i})-a(\\overrightarrow{x}_{i})}{\\max{[a(\\overrightarrow{x}_{i}),b(\\overrightarrow{x}_{i})]}}}  \\end{aligned}\\]          $a(\\overrightarrow{x}{i})$ : 관측치 벡터 $\\overrightarrow{x}{i}$ 기준 군집 내 응집도로서, 해당 관측치와 같은 군집에 속한 관측치와의 평균 거리      $b(\\overrightarrow{x}{i})$ : 관측치 벡터 $\\overrightarrow{x}{i}$ 기준 군집 간 분리도로서, 해당 관측치와 다른 군집에 속한 관측치와의 평균 거리 중 최소값      이미지 출처  https://www.scaler.com/topics/supervised-and-unsupervised-learning/  https://towardsdatascience.com/a-brief-introduction-to-unsupervised-learning-20db46445283  https://tyami.github.io/machine%20learning/clustering/"
  },
  
  {
    "title": "tSNE",
    "url": "/posts/tSNE/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Feature Engineering",
    "date": "2024-01-12 00:00:00 +0900",
    





    
    "snippet": "What? t-SNEStochastic Neighbor Embedding      정의 : 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소      t-distributed Stochastic Neighbor Embedding      SNE의 문제점 : Crowding Problem              ...",
    "content": "What? t-SNEStochastic Neighbor Embedding      정의 : 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소      t-distributed Stochastic Neighbor Embedding      SNE의 문제점 : Crowding Problem              가우시안 분포는 양쪽 꼬리 부분이 충분히 두텁지 않은 형태를 보임                                                  즉, 확률변수 $                             \\overrightarrow{x}{i}-\\overrightarrow{x}{j}                             $ 가 일정한 값 이상부터는 유사도에 큰 차이가 없음                                                t-SNE의 해결책 : Student t-Dristribution    \\[\\begin{aligned}  T  &amp;= \\frac{Z}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}}\\\\  V  &amp;= \\sum_{i=1}^{k}{Z_{i}^{2}}  \\end{aligned}\\]          $Z$ : 표준 가우시안 분포      $V$ : 자유도가 $\\nu$ 인 카이제곱 분포      수학적 이해두 관측치의 고차원 공간 상 유사도 도출      확률변수 $X$ 가 가우시안 분포 $N(\\mu, \\sigma^{2})$ 을 따른다고 했을 때, $X$ 의 확률밀도함수는 다음과 같음\\[\\begin{aligned}  f(x)  &amp;= \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}  \\end{aligned}\\]        관측치 $\\overrightarrow{x}{i}$ 로부터의 거리에 대한 $\\overrightarrow{x}{i}$ 와의 유사도의 가우시안 분포에 기초했을 때, $\\overrightarrow{x}{j}$ 가 $\\overrightarrow{x}{i}$ 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  p_{j|i}   = \\frac{\\exp{\\left[-\\frac{||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}||^{2}}{2\\sigma^{2}}\\right]}}{\\sum_{k \\ne i}{\\exp{\\left[-\\frac{||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{k}||^{2}}{2\\sigma^{2}}\\right]}}}\\\\\\\\  ||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|| \\sim N_{i}(0,\\sigma^{2})  \\end{aligned}\\]        또한 관측치 $\\overrightarrow{x}{j}$ 로부터의 거리에 대한 $\\overrightarrow{x}{j}$ 와의 유사도의 가우시안 분포에 기초했을 때, $\\overrightarrow{x}{i}$ 가 $\\overrightarrow{x}{j}$ 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  p_{i|j}  = \\frac{\\exp{\\left[-\\frac{|\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|^{2}}{2\\sigma^{2}}\\right]}}{\\sum_{k \\ne j}{\\exp{\\left[-\\frac{|\\overrightarrow{x}_{j}-\\overrightarrow{x}_{k}|^{2}}{2\\sigma^{2}}\\right]}}}\\\\\\\\  ||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|| \\sim N_{j}(0,\\sigma^{2})  \\end{aligned}\\]        두 가능성은 서로 다른 확률 분포에 기초하고 있으므로 그 값이 반드시 일치한다고 볼 수 없음\\[p_{j|i} \\ne p_{i|j}\\]        따라서 $\\overrightarrow{x}{i}$ 와 $\\overrightarrow{x}{j}$ 의 유사도를 다음과 같이 정의함\\[\\begin{aligned}  p_{i,j}  &amp;= \\frac{p_{j|i} + p_{i|j}}{2n}  \\end{aligned}\\]  두 관측치의 2차원 공간 상 유사도 도출      관측치 $\\overrightarrow{y}{i}$ 로부터의 거리에 대한 $\\overrightarrow{y}{i}$ 와의 유사도의 가우시안 분포에 기초했을 때, $\\overrightarrow{y}{j}$ 가 $\\overrightarrow{y}{i}$ 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  q_{j|i}   = \\frac{\\exp{\\left[-||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{j}||^{2}\\right]}}{\\sum_{k \\ne i}{\\exp{\\left[-||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{k}||^{2}\\right]}}}\\\\\\\\  ||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{j}|| \\sim N_{i}(0,\\sigma^{2})  \\end{aligned}\\]          $\\overrightarrow{y}$ : 고차원 공간 상의 관측치 벡터 $\\overrightarrow{x}$ 를 2차원 공간 상에 매핑한 벡터            $\\overrightarrow{y}{i}$ 와 $\\overrightarrow{y}{j}$ 의 유사도를 다음과 같이 정의함\\[\\begin{aligned}  q_{i,j}  &amp;= \\frac{q_{j|i} + q_{i|j}}{2n}  \\end{aligned}\\]  비용함수를 최소화하는 아규먼트 도출      KL(Kullback-Leibler Divergence) : 확률변수 $X$ 의 동일한 아규먼트 $x_{i}$ 에 대하여 두 확률 분포 $P,Q$ 의 차이를 측정하는 지표\\[\\text{KL}(P|Q)  = \\sum_{i=1}^{n}{P(X=x_{i})\\cdot\\log{\\frac{P(X=x_{i})}{Q(X=x_{i})}}}\\]        KL에 기초한 비용함수 정의\\[\\begin{aligned}  Cost  &amp;= \\sum_{i}{\\text{KL}(P_{i}|Q_{i})}\\\\  &amp;= \\sum_{i}{\\sum_{j}{p_{i,j}\\cdot\\log{\\frac{p_{i,j}}{q_{i,j}}}}}  \\end{aligned}\\]        $\\hat{\\mathbf{Y}}$ 도출\\[\\begin{aligned}  \\hat{\\mathbf{Y}}  &amp;= \\{\\hat{\\overrightarrow{y}}_{i}|\\argmin_{\\overrightarrow{y}_{i}}{Cost}\\}  \\end{aligned}\\]  sklearn.manifold.TSNEfrom sklearn.manifold import TSNEGeneral HyperParameter  random_state = None  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter  n_components(default : 2) : 축소할 차원의 갯수  metric(default : 'euclidean') : 관측치 간 기하 거리 측정 방법  perplexity(default : 30.0) : 참조할 Nearest Neighbors 갯수로서 5~50 사이의 값을 권장함  early_exaggeration(default :12.0) : perplexity 에 기초하여 형성된 군집 간 거리Learning Task HyperParameter  learning_rate(default : 'auto') : 학습률  n_iter(default : 1000) : 다양체 탐색 횟수로서 250 이상의 값을 권장함  n_iter_without_progress(default : 300) : 손실 함수가 몇 번 이상 개선되지 않을 경우 학습을 중단할 것인가"
  },
  
  {
    "title": "PCA & LDA",
    "url": "/posts/PCA&LDA/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Feature Engineering",
    "date": "2024-01-11 00:00:00 +0900",
    





    
    "snippet": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90\\degree}  &a...",
    "content": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90\\degree}  &amp;= \\frac{(\\overrightarrow{a}-p\\overrightarrow{b})^{T}\\overrightarrow{b}}{||\\overrightarrow{a}||\\cdot||\\overrightarrow{b}||}\\\\  &amp;= 0\\\\  \\therefore \\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})  &amp;= p\\overrightarrow{b}\\\\  &amp;= \\left(\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{||\\overrightarrow{b}||^{2}}\\right)\\overrightarrow{b}  \\end{aligned}\\]                                                      $p=\\displaystyle\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{                             \\overrightarrow{b}                             ^{2}}$ : 정사영 벡터의 크기                                          $\\overrightarrow{b}$ : 정사영 벡터의 방향      Covariance Matrix      공분산(Covariance) : 두 확률변수의 선형관계를 나타내는 지표로서, 두 확률변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]        공분산행렬(Covariance Matrix) : $n$ 개 변수들 간 공분산을 나열한 $n \\times n$ 정방행렬\\[\\Sigma=  \\begin{matrix}  &amp; \\overrightarrow{A} &amp; \\overrightarrow{B} &amp; \\overrightarrow{C} \\\\  \\overrightarrow{A} &amp; \\sigma_{A}^2 &amp; \\sigma_{AB} &amp; \\sigma_{AC} \\\\  \\overrightarrow{B} &amp; \\sigma_{BA} &amp; \\sigma_{B}^2 &amp; \\sigma_{BC} \\\\  \\overrightarrow{C} &amp; \\sigma_{CA} &amp; \\sigma_{CB} &amp; \\sigma_{C}^2  \\end{matrix}\\]  Linear Transformation      행렬 $\\mathbf{X}$ 을 통한 선형변환은 어떤 좌표를 $\\begin{pmatrix}1\\0\\end{pmatrix},\\begin{pmatrix}0\\1\\end{pmatrix}$ 를 기저로 사용하는 2차원 좌표계에서 $\\overrightarrow{x}{1},\\overrightarrow{x}{2}$ 를 기저로 사용하는 2차원 좌표계로 변환하는 것을 의미함\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix} \\overrightarrow{x}_{1}&amp;\\overrightarrow{x}_{2} \\end{pmatrix}  \\end{aligned}\\]        벡터 $\\overrightarrow{v}$ 는 $\\begin{pmatrix}1\\0\\end{pmatrix},\\begin{pmatrix}0\\1\\end{pmatrix}$ 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 를 나타냄\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= -1\\begin{pmatrix}1\\\\0\\end{pmatrix} + 2\\begin{pmatrix}0\\\\1\\end{pmatrix}\\\\  \\end{aligned}\\]        $\\mathbf{X}$ 를 통한 선형 변환 결과 $\\overrightarrow{v}$ 는 $\\overrightarrow{x}{1},\\overrightarrow{x}{2}$ 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 로 변환되었음\\[\\begin{aligned}  \\mathbf{X}\\cdot\\overrightarrow{v}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\cdot \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix}-5\\\\2\\end{pmatrix}\\\\  &amp;= -1\\overrightarrow{x}_{1} + 2\\overrightarrow{x}_{2}  \\end{aligned}\\]  Eigen-Vector      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A_n$ 으로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 $\\overrightarrow{0}$ 이 아닌 벡터\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]        고유값(Eigen-Value; $\\lambda$) : 고유벡터의 선형변환 전 크기 대비 선형변환 후 크기의 비율  PCAPrincipal Component Analysis      정의 : 고차원 데이터에 대하여, X의 방향적 분포를 가장 잘 설명하는 새로운 저차원 직교 좌표를 학습하는 기법              주성분(Principal Component; PC) : 새로운 저차원 직교 좌표            방법 : 관측치 간 상대적 특성을 잘 보존하는 성분들을 추출함              $\\text{component}$ : 주성분 벡터 $\\overrightarrow{w}$      $\\text{datapoint}$ : 관측치 벡터 $\\overrightarrow{x}\\in \\mathbf{X}$      $\\text{projected data}$ : 주성분 벡터에 대한 관측치 벡터의 정사영 벡터 $\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{x})$      $D_{1}$ : 관측치 벡터에 대하여 보존하는 정보로서 분산      $D_{2}$ : 관측치 벡터에 대하여 유실하는 정보      $D_{3}$ : 관측치 벡터의 본래 정보      주성분 도출 과정의 이해      관측치 행렬 $X_{N \\times P}$ 를 단위벡터 $\\overrightarrow{w}$ 에 정사영한다고 하자\\[\\begin{aligned}  proj_{\\overrightarrow{w}}(\\mathbf{X})  &amp;= \\frac{&lt;\\mathbf{X},\\overrightarrow{w}&gt;}{||w||^2}\\cdot\\overrightarrow{w}\\\\  &amp;= (\\overrightarrow{w}^{T}\\mathbf{X})\\cdot\\overrightarrow{w}(\\because ||w||=1)  \\end{aligned}\\]          $\\overrightarrow{w}$ : 정사영 벡터의 방향      $\\overrightarrow{w}^{T}\\mathbf{X}$ : 정사영 벡터의 크기            $\\overrightarrow{w}$ 에 정사영된 관측치들의 분산 $\\mathbf{V}$ 은 다음과 같음\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w})\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}  \\end{aligned}\\]          $\\Sigma=\\displaystyle\\frac{1}{n}\\mathbf{X}\\mathbf{X}^{T}$ : 관측치 행렬 $X$ 의 공분산 행렬            $\\mathbf{V}$ 을 최대화하는 $\\overrightarrow{w}$ 를 채택한다고 하자\\[\\hat{\\overrightarrow{w}}  = \\argmax_{\\overrightarrow{w}}{\\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}}\\\\  \\begin{aligned}  \\\\\\text{s.t.} \\quad  &amp; \\overrightarrow{w}^{T}\\overrightarrow{w}=1  \\end{aligned}\\]        라그랑주 승수법에 기초하여 $\\hat{\\overrightarrow{w}}$ 도출\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\overrightarrow{w}}  &amp;= \\Sigma\\overrightarrow{w}-\\lambda\\overrightarrow{w}\\\\  &amp;= 0\\\\\\\\  \\therefore (\\Sigma-\\lambda\\mathbf{I})\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]        $\\mathbf{V}$ 를 최대화하는 주성분 $\\overrightarrow{w}$ 은 $\\mathbf{X}$ 의 공분산 행렬 $\\Sigma$ 의 고유벡터임\\[\\begin{aligned}  \\Sigma  &amp;= \\mathbb{V}\\mathbb{\\Lambda}\\mathbb{V}^{-1},\\\\  \\mathbb{V}  &amp;= \\begin{pmatrix}\\overrightarrow{w}_{1}&amp;\\overrightarrow{w}_{2}&amp;\\cdots&amp;\\overrightarrow{w}_{p}\\end{pmatrix}\\\\  \\mathbb{\\Lambda}  &amp;= \\text{diag}(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{p})  \\end{aligned}\\]  주성분 벡터의 설명력 이해      주성분 벡터의 고유값 : 관측치 행렬 $\\mathbf{X}$ 에 대하여 주성분 벡터에 대한 정사영 벡터 간 분산\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}\\\\  &amp;= \\hat{\\overrightarrow{w}}^{T}\\lambda\\hat{\\overrightarrow{w}}(\\because \\Sigma\\hat{\\overrightarrow{w}}-\\lambda\\hat{\\overrightarrow{w}}=0)\\\\  &amp;= \\lambda(\\because \\overrightarrow{w}^{T}\\overrightarrow{w}=1)  \\end{aligned}\\]        주성분 벡터의 설명력 : 관측치 행렬 $\\mathbf{X}_{N \\times P}$ 에 대하여 생성 가능한 $P$ 개의 주성분 벡터 고유값 합계 대비 해당 주성분 벡터 고유값 비율\\[\\frac{\\lambda_{k}}{\\sum_{i=1}^{p}{\\lambda_{i}}}\\]  LDALinear Discriminant Analysis      정의 : 고차원 데이터에 대하여, 주어진 클래스를 가장 잘 구분할 수 있는 새로운 저차원 직교 좌표를 찾는 기법            방법 : 클래스 간 분산은 최대화하는 동시에 클래스 내 관측치 간 분산은 최소화하는 성분들을 추출함\\[\\hat{\\overrightarrow{w}}  =\\argmax_{\\overrightarrow{w}}{\\frac{\\Sigma^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}}\\\\  \\begin{aligned}  \\\\\\text{s.t.} \\quad  &amp; \\overrightarrow{w}^{T}\\overrightarrow{w}=1  \\end{aligned}\\]          $\\Sigma^{2}$ : 정사영 후 클래스 간 분산      $\\sigma_{i}^{2}$ : 정사영 후 $i$ 번째 클래스 내 관측치 간 분산      선형 판별 함수 도출 과정의 이해      정사영 후 범주 간 분산 $\\Sigma^{2}$\\[\\begin{aligned}  \\Sigma^{2}  &amp;= (\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})(\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})^{T}\\\\  &amp;= (\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})(\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})^{T}\\quad(\\because \\overrightarrow{\\mu}_{i}=\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})\\\\  &amp;= \\overrightarrow{w}^{T}(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}  \\end{aligned}\\]          $\\overrightarrow{m}{i}$ : $i$ 번째 범주 $C{i}$ 의 중심점 벡터      $\\overrightarrow{\\mu}{i}=\\text{proj}{\\overrightarrow{w}}(\\overrightarrow{m}{i})$ : $\\overrightarrow{m}{i}$ 의 정사영 벡터      $\\mathbf{S}{B}$ : 범주 $C{i},C_{j}$ 간 편차      $\\Sigma$ : 정사영 후 범주 $C_{i},C_{j}$ 간 편차            정사영 후 범주 내 분산 $\\sigma_{i}^{2}$\\[\\begin{aligned}  \\sigma_{i}^{2}  &amp;= \\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})^{T}}\\quad(\\overrightarrow{x}_{j} \\in C_{i})\\\\  &amp;= \\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})^{T}}\\quad(\\because \\overrightarrow{y}_{j}=\\overrightarrow{w}^{T}\\overrightarrow{x}_{j})\\\\  &amp;= \\overrightarrow{w}^{T}\\left[\\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})^{T}}\\right]\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{i}\\overrightarrow{w}  \\end{aligned}\\]          $\\overrightarrow{x}{j} \\in C{i}$ : $i$ 번째 범주 $C_{i}$ 의 $j$ 번째 관측치 벡터      $\\overrightarrow{y}{j}=\\text{proj}{\\overrightarrow{w}}(\\overrightarrow{x}{j})$ : $\\overrightarrow{x}{j}$ 의 정사영 벡터      $S_{i}$ : $i$ 번째 범주 $C_{i}$ 의 범주 내 관측치 간 편차      $\\sigma_{i}$ : 정사영 후 $i$ 번째 범주 $C_{i}$ 의 범주 내 관측치 간 편차            목적 함수 재정의\\[\\hat{\\overrightarrow{w}}  =\\argmax_{\\overrightarrow{w}}{\\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}}\\\\  \\begin{aligned}  \\\\\\text{s.t.} \\quad  &amp; \\overrightarrow{w}^{T}\\overrightarrow{w}=1  \\end{aligned}\\]        라그랑주 승수법을 통한 최적화 문제 풀이\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\partial \\overrightarrow{w}}  &amp;= 0\\\\\\\\  \\therefore \\left[\\mathbf{S}_{B}^{-1}(\\mathbf{S}_{1}+\\mathbf{S}_{2})-\\lambda\\mathbf{I}\\right]\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]  sklearn.decomposition.PCAfrom sklearn.decomposition import PCAGeneral HyperParameter  random_state = NoneModel HyperParameter  n_components(default : 5) : 축소할 차원의 개수  whiten(default : False) : Standard Scaling 여부Attribute  n_features_ : 축소 전 차원의 개수  feature_names_in_ : 축소 전 차원명  mean_ : 축소 전 차원별 평균  n_components_ : 축소 후 차원의 개수  components_ : 고유벡터  explained_variance_ : 각 고유벡터의 고유값  explained_variance_ratio_ : 전체 고유벡터의 고유값 대비 각 고유벡터의 고유값이미지 출처  http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/  https://github.com/lovit/python_ml_intro"
  },
  
  {
    "title": "Curse of Dimensionality",
    "url": "/posts/Curse_of_Dimensionality/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Unsupervised Learning, Feature Engineering",
    "date": "2024-01-10 00:00:00 +0900",
    





    
    "snippet": "Curse of Dimensionality차원의 저주      정의 : 고차원일수록 알고리즘이 제대로 학습하지 못하는 현상              관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해짐            차원 축소의 당위성              Manifold hypothesis      Many hig...",
    "content": "Curse of Dimensionality차원의 저주      정의 : 고차원일수록 알고리즘이 제대로 학습하지 못하는 현상              관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해짐            차원 축소의 당위성              Manifold hypothesis      Many high-dimensional data sets that occur in the real world actually lie along low-dimensional latent manifolds inside that high-dimensional space.      차원 축소 기법의 종류  차원 선택(Feature Selection) : 유효한 차원을 선별하는 방법          Filter Approach                  Odds Ratio                    Wrapper Approach                  Forward Selection          Backward Elimination          Stepwise Selection                      차원 추출(Feature Extraction) : 원본의 특징을 보존하는 새로운 차원을 추출하는 방법          $\\argmax_{\\overrightarrow{w}}{\\sigma^{2}}$                  주성분 분석(Principle Component Analysis; PCA)          선형 판별 분석(Linear Discriminant Analysis; LDA)                    $\\argmax_{\\overrightarrow{w}}{dist}$                  다차원 척도법(Multi-Dimensional Scaling; MDS)                    Reveal Non-Linear Structure                  t-SNE(t-distributed Stochastic Neighbor Embedding)          LLE(Locally Linear Embedding)          ISOMAP(ISOmetric feature MAPping)                    Feature Selection  Occam’s Razor  Entities should not be multiplied beyond necessity.Filter Approach      승산(Odds) : 변수 $Y$ 가 반응할 가능성이 반응하지 않을 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{odds}(Y)  &amp;= \\frac{P(Y=1)}{1-P(Y=1)}  \\end{aligned}\\]        승산비(Odds Ratio; OR) : 변수 $X$ 가 참일 때 $Y$ 가 반응할 가능성이, $X$ 가 거짓일 때 $Y$ 가 반응할 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{OR}(Y|X)  &amp;= \\frac{\\text{odds}(X=1)}{\\text{odds}(X=0)}\\\\  &amp;= \\frac{\\frac{P(Y=1\\big|X=1)}{1-P(Y=1\\big|X=1)}}{\\frac{P(Y=1\\big|X=0)}{1-P(Y=1\\big|X=0)}}  \\end{aligned}\\]                                                      $\\text{OR}(Y              X) = 1$ : $X$ 의 변동이 $Y$ 의 변동에 영향을 미치지 않음                                                                                      $\\text{OR}(Y              X) &lt; 1$ : $X$ 는 $Y$ 와 음의 상관관계에 있음                                                                                      $\\text{OR}(Y              X) &gt; 1$ : $X$ 는 $Y$ 와 양의 상관관게에 있음                                                로지스틱 회귀식 가중치와 승산비의 상관관계 이해                  단순 회귀 분석 하 로지스틱 회귀식은 다음과 같음\\[\\ln{\\frac{P(Y=1)}{1-P(Y=1)}}  =\\beta_0 + \\beta_1 X\\]                    $X=1$ 일 때의 로지스틱 회귀식\\[\\begin{aligned}  \\ln{\\displaystyle\\frac{P(Y=1 \\Big| X=1)}{1-P(Y=1 \\Big| X=1)}}  &amp;= \\beta_0 + \\beta_1 \\times 1 \\\\  &amp;= \\beta_0 + \\beta_1  \\end{aligned}\\]                    $X=0$ 일 때의 로지스틱 회귀식\\[\\begin{aligned}  \\ln{\\displaystyle\\frac{P(Y=1 \\Big| X=0)}{1-P(Y=1 \\Big| X=0)}}  &amp;= \\beta_0 + \\beta_1 \\times 0 \\\\  &amp;= \\beta_0  \\end{aligned}\\]                    두 회귀식을 빼면 다음과 같음\\[\\begin{aligned}  &amp;\\ln{\\displaystyle\\frac{P(Y=1 \\Big| X=1)}{1-P(Y=1 \\Big| X=1)}} - \\ln{\\displaystyle\\frac{P(Y=1 \\Big| X=0)}{1-P(Y=1 \\Big| X=0)}}\\\\  &amp;= \\ln{\\frac{\\frac{P(Y=1 \\big| X=1)}{1-P(Y=1 \\big| X=1)}}{\\frac{P(Y=1 \\big| X=0)}{1-P(Y=1 \\big| X=0)}}}\\\\  &amp;= (\\beta_0 + \\beta_1) - \\beta_0\\\\  &amp;= \\beta_1  \\end{aligned}\\]                                                        따라서 설명변수 $X$ 의 가중치 $\\beta_1$ 과 승산비 $\\text{OR}(Y              X)$ 간에는 다음과 같은 관계가 성립함                              \\[\\begin{aligned}  \\therefore \\text{OR}(Y|X)  &amp;= \\frac{\\frac{P(Y=1 \\big| X=1)}{1-P(Y=1 \\big| X=1)}}{\\frac{P(Y=1 \\big| X=0)}{1-P(Y=1 \\big| X=0)}} \\\\  &amp;= \\exp[\\beta_1]  \\end{aligned}\\]            Wrapper Approach      Forward Selection : 어떤 변수도 선택되지 않은 상태에서 가장 설명력이 좋은 변수를 하나씩 추가하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\argmax_{x_{i}}R^2[y,f(x_{i})]\\\\  \\hat{x}_{j}&amp;=\\argmax_{x_{j}}R^2[y,f(x_{j \\ne i};\\hat{x}_{i})]\\\\  \\hat{x}_{k}&amp;=\\argmax_{x_{k}}R^2[y,f(x_{k \\ne i,j};\\hat{x}_{i},\\hat{x}_{j})]  \\end{aligned}\\\\  \\vdots\\]        Backward Elimination : 모든 변수가 포함된 상태에서 시작하여 불필요한 변수를 하나씩 제거하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\argmax_{x_{i}}R^2[y,f(\\not{x_{i}})]\\\\  \\hat{x}_{j}&amp;=\\argmax_{x_{j}}R^2[y,f(\\not{x_{j \\ne i}};\\not{\\hat{x}_{i}})]\\\\  \\hat{x}_{k}&amp;=\\argmax_{x_{k}}R^2[y,f(\\not{x_{k \\ne i,j}};\\not{\\hat{x}_{i}},\\not{\\hat{x}_{j}})]  \\end{aligned}\\\\  \\vdots\\]        Stepwise Selection : 어떤 변수도 선택되지 않은 상태에서 Forward Selection 과 Backward Elimination 을 번갈아 수행하는 방법  Metrics      Akaike Information Criteria(AIC)\\[\\begin{aligned}  \\text{AIC}  &amp;= -2\\ln{\\hat{L}}+2k  \\end{aligned}\\]                  $\\hat{L}$ : 모델 적합도로서 $\\overrightarrow{x}{i}$ 가 주어졌을 때 $y{i}$ 가 발생할 가능성\\[\\begin{aligned}  \\hat{L}  &amp;= \\prod_{i=1}^{n}{P(Y=y_{i}|X=\\overrightarrow{x}_{i};\\hat{\\overrightarrow{\\theta}})}\\\\  \\hat{\\overrightarrow{\\theta}}  &amp;= \\begin{pmatrix}\\hat{\\beta_{0}}&amp;\\hat{\\beta_{1}}&amp;\\cdots&amp;\\hat{\\beta_{d}}\\end{pmatrix}  \\end{aligned}\\]                    $k$ : 모델 복잡도                  Bayesian Information Criteria(BIC)\\[\\begin{aligned}  \\text{BIC}  &amp;= -2\\ln{\\hat{L}}+k\\ln{n}  \\end{aligned}\\]  이미지 출처  https://www.incodom.kr/%EC%B0%A8%EC%9B%90%EC%B6%95%EC%86%8C#h_85f3fb207a586b3f9b5702a3be7799e1  http://matrix.skku.ac.kr/math4ai-intro/W12/"
  },
  
  {
    "title": "Logistic Regression",
    "url": "/posts/Logistic_Regression/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Regression",
    "date": "2024-01-09 00:00:00 +0900",
    





    
    "snippet": "What? Logistic RegressionLogistic Regression      정의 : 회귀 기법을 판별분석에 활용하는 비선형 함수 알고리즘    \\[P(c=1)  = \\frac{1}{1+\\exp[-(\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d})]}\\]  Logistic Function      설명변...",
    "content": "What? Logistic RegressionLogistic Regression      정의 : 회귀 기법을 판별분석에 활용하는 비선형 함수 알고리즘    \\[P(c=1)  = \\frac{1}{1+\\exp[-(\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d})]}\\]  Logistic Function      설명변수와 반응변수 가정                  어떠한 관측치 벡터 $\\overrightarrow{x}$ 가 다음과 같이 주어졌다고 하자\\[\\begin{aligned}  f(\\overrightarrow{x})  &amp;=\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d} \\in (-\\infty,\\infty)  \\end{aligned}\\]                    $\\overrightarrow{x}$ 의 반응변수 $y$ 는 다음과 같음\\[\\begin{aligned}  y  &amp;=c \\in \\{0,1\\}  \\end{aligned}\\]                    $y$ 와 $\\overrightarrow{x}$ 간에는 공역이 일치하지 않으므로 등식이 성립하지 않음\\[y \\ne \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}\\]                  반응변수 재정의 : 범주 $1$ 에 속할 확률\\[\\begin{aligned}  y  &amp;= P(c=1) \\in [0,1]  \\end{aligned}\\]        공역 조정을 통한 연결함수 $f(x)$ 도출                  승산(Odds) : 범주 $1$ 에 속하지 않을 확률 대비 속할 확률\\[\\begin{aligned}  f(x)  &amp;= \\text{odds}\\\\  &amp;= \\frac{P(c=1)}{1-P(c=1)} \\in [0, \\infty)  \\end{aligned}\\]                    로짓(Logit) : 승산에 자연로그를 취한 값\\[\\begin{aligned}  f(x)  &amp;= \\text{logit}\\\\  &amp;= \\ln{\\frac{P(c=1)}{1-P(c=1)}} \\in (-\\infty, \\infty)  \\end{aligned}\\]                    로짓 함수와 $\\overrightarrow{x}$ 연결\\[\\begin{aligned}  \\text{logit}  &amp;= f(x)\\\\  &amp;= \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}  \\end{aligned}\\]                  연결함수를 활용하여 재정의된 반응변수와 설명변수 연결\\[\\begin{aligned}  \\ln{\\frac{P(c=1)}{1-P(c=1)}}  &amp;= f(x)\\\\  &amp;= \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}\\\\\\\\  \\frac{P(c=1)}{1-P(c=1)}  &amp;= e^{f(x)}\\\\  &amp;= \\exp[\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}]\\\\\\\\  \\therefore  y  &amp;= P(c=1)\\\\  &amp;= \\frac{1}{1+\\exp[-(\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d})]}  \\end{aligned}\\]  sklearn.linear_model.LogisticRegressionfrom sklearn.linear_model import LogisticRegressionGeneral HyperParameter  random_state(default : None)  warm_start(default : False) : 동작 메시지 출력 여부 설정  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter  solver(default : 'lbfgs') : 회귀식 종류로서 그 아규먼트에 따라 penalty 의 아규먼트가 한정됨          'lbfgs' : l2 or None      'liblinear' : l1 or l2      'newton-cg' : l2 or None      'newton-cholesky' : l2 or None      'sag' : l2 or None      'saga' : elasticnet, l1, l2 or None            fit_intercept(default : True) : 상수항 $\\beta_0$ 설정 여부    multi_class(default : 'auto') : 다항 분류 시 분류 규칙 설정          'auto' : 이항 분류 혹은 solver 아규먼트가 'liblinear' 인 경우 'ovr', 그외에는 'multinomial' 을 선택함      'ovr' : One VS Rest      'multinomial' : solver 아규먼트가 'liblinear' 인 경우 적용 불가      To Prevent OverFitting      max_iter(default : 100) : 최적 회귀계수 탐색 최대 횟수        tol(default : 0.0001) : 허용 오차    penalty(default : l2) : 가중치 규제 방법          None      'l1' : LASSO      'l2' : Ridge      'elasticnet' : l1, l2 혼합            C(default : 1.0) : 가중치 규제 시 규제 강도    l1_ratio(default : None) : elasticnet 설정 시 전체 규제 강도 대비 l1 규제 비중To Prevent Underfitting  class_weight(default : None) : 가중할 범주와 그 값          'balanced'      dictionary type      "
  },
  
  {
    "title": "Linear Regression",
    "url": "/posts/Linear_Regression/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Regression",
    "date": "2024-01-08 00:00:00 +0900",
    





    
    "snippet": "What? Regression      정의 : 반응변수와 그 설명변수 간 상관관계 추세를 요약하는 수렴 작업    설명변수의 개수에 따른 구분                  단순 회귀 모형(Simple Regression Model) : 반응변수에 대한 설명변수가 하나인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1X+\\vareps...",
    "content": "What? Regression      정의 : 반응변수와 그 설명변수 간 상관관계 추세를 요약하는 수렴 작업    설명변수의 개수에 따른 구분                  단순 회귀 모형(Simple Regression Model) : 반응변수에 대한 설명변수가 하나인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1X+\\varepsilon\\]                    다중 회귀 모형(Multiple Regression Model) : 반응변수에 대한 설명변수가 두 가지 이상인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\cdots+\\beta_k X_k+\\varepsilon\\]              선형 가정 여부에 따른 구분          선형 회귀 모형(Linear Regression Model) : 설명변수와 반응변수 간 선형관계를 가정하는 경우                  sklearn.linear_model.LinearRegression          sklearn.linear_model.SGDRegressor                    비선형 회귀 모형(Non-Linear Regression Model) : 설명변수와 반응변수 간 선형관계를 가정하지 않는 경우                  sklearn.svm.SVR          sklearn.tree.DecisionTreeRegressor                    Linear Regression단순 선형 회귀 모형      단순 선형 회귀 모형의 이해\\[\\begin{aligned}  &amp;Y=\\beta_0+\\beta_1X+\\varepsilon\\\\  &amp;\\Rightarrow y_i=\\beta_0+\\beta_1x_i+\\varepsilon_i  \\end{aligned}\\]          $\\varepsilon$ : 잔차항(Residual)                  $E[\\varepsilon]=0$                            $\\beta_0$ : 편향(Bias)            $\\beta_1$ : 가중치(Weight)            최소자승법에 기초한 회귀계수 최적값 도출                  최소자승법(Least Square Method; OLS) : 회귀계수 최적값을 잔차항 $\\varepsilon_{i}$ 자승의 합계를 최소화하는 값으로 탐색하는 방법\\[\\begin{aligned}  \\hat{\\beta_{0}},\\hat{\\beta_{1}}  &amp;= \\argmin_{\\beta_{0},\\beta_{1}}{L_{OLS}}  \\end{aligned}\\]                    최소자승법에 기초한 손실 함수 $L_{OLS}$\\[\\begin{aligned}  L_{OLS}  &amp;= \\sum_{i=1}^{n}{\\varepsilon_{i}^2}\\\\  \\varepsilon_{i}  &amp;= y_{i}-\\hat{y}_{i}\\\\  &amp;= y_{i}-(\\beta_{0}+\\beta_{1}\\hat{x}_{i})  \\end{aligned}\\]                    최소자승법에 기초한 회귀계수 $\\beta_{0}$ 의 최적값 $\\hat{\\beta_{0}}$\\[\\begin{aligned}  \\hat{\\beta_{0}}  &amp;= \\overline{y}-\\beta_{1}\\overline{x}  \\end{aligned}\\]                    최소자승법에 기초한 회귀계수 $\\beta_{1}$ 의 최적값 $\\hat{\\beta_{1}}$\\[\\begin{aligned}  \\hat{\\beta_{1}}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})(y_{i}-\\overline{y})}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\  &amp;=\\frac{\\sigma_{xy}}{\\sigma_{x}^{2}}  \\end{aligned}\\]            다중 선형 회귀 모형      관측치 $i$ 에 대한 다중 선형 회귀 모형이 다음과 같다고 하자\\[y_{i}=\\beta_{0}+\\beta_{1}x_{i,1}+\\beta_{2}x_{i,2}+\\cdots+\\beta_{d}x_{i,d}\\]          $i\\in{1,2,\\cdots,n}$ : 관측치 번호      $k\\in{1,2,\\cdots,d}$ : 설명변수 번호            $n$ 개의 관측치가 존재한다고 했을 때 위 모형을 선형대수로 표현할 수 있음\\[\\hat{\\overrightarrow{y}} = \\hat{\\mathbf{X}}\\overrightarrow{\\beta}\\]        최소자승법에 기초하여 도출한 가중치 벡터를 정규방정식(Normal Equation)이라고 정의함\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= \\argmin_{\\overrightarrow{\\beta}}{L_{OLS}}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]  가중치 규제(Weight Regulation)      p-norm : $n$ 차원 벡터 $\\overrightarrow{x}=\\begin{pmatrix}x_{1}&amp;x_{2}&amp;\\cdots&amp;x_{n}\\end{pmatrix}$ 의 크기를 정의하는 방법    \\[||x||_{p}=(|x_{1}|^{p}+|x_{2}|^{p}+\\cdots+|x_{n}|^{p})^{\\frac{1}{p}}\\]        가중치 규제(Weight Regulation) : 회귀계수 최적값을 탐색함에 있어 회귀계수 벡터 $\\overrightarrow{\\beta}$ 의 크기에 제약을 두는 것    \\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}  &amp;= \\argmin_{\\overrightarrow{\\beta}}{\\left[L_{OLS}+\\lambda||\\beta||_{p}^{2}\\right]}  \\end{aligned}\\]                  $L_{OLS}(\\overrightarrow{\\beta})$ : 최소자승법에 기초한 손실 함수                    $\\overrightarrow{\\beta}$ : 회귀계수 벡터                    $\\lambda$ : 회귀계수 벡터 $\\overrightarrow{\\beta}$ 크기 제약 강도                    p : 벡터 크기 정의 방법                  p=1 : LASSO          p=2 : Ridge                    경사하강법(Gradient Descent)      그라디언트(Gradient) : 다변수 함수에 대하여 모든 방향으로의 순간변화율 벡터    \\[\\begin{aligned}  \\nabla{f(x_{1},x_{2},\\cdots,x_{n})}  &amp;= \\begin{pmatrix}  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{1}}\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{2}}\\\\  \\vdots\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{n}}\\\\  \\end{pmatrix}  \\end{aligned}\\]        경사하강법(Gradient Descent) : 회귀계수 최적값을 탐색함에 있어 손실 함수의 그라디언트를 활용하는 방법            절차          회귀계수 벡터 $\\overrightarrow{w}$ 의 초기 아규먼트 설정      현재 아규먼트 $\\overrightarrow{w}{prev}$ 에서 손실 함수의 그라디언트 $\\nabla{L{OLS}(\\overrightarrow{w}_{prev})}$ 계산      현재의 아규먼트에서 음의 방향으로 $\\alpha \\times \\nabla{L_{OLS}(\\overrightarrow{w}{prev})}$ 만큼 이동하여 새로운 아규먼트 $\\overrightarrow{w}{new}$ 적용      ②, ③을 반복하여 손실 함수를 최소화하는 지점 탐색            회귀계수 갱신 규칙\\[\\begin{aligned}  \\overrightarrow{w}_{new}  &amp;= \\overrightarrow{w}_{prev} - \\alpha \\times \\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}  \\end{aligned}\\]          $\\overrightarrow{w}_{prev}$ : 현재 회귀계수 아규먼트      $\\overrightarrow{w}_{new}$ : 새로운 회귀계수 아규먼트      $\\alpha$ : 학습률      $\\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}$ : 최소자승법에 기초하여 도출한 손실 함수의 그라디언트            학습률(Learning Rate) : 손실 함수에 대하여 그 극소점을 탐색하기 위한 회귀계수 갱신 보폭                  학습률이 낮을수록 과대적합될 가능성이 높음                            학습률이 높을수록 과소적합될 가능성이 높음                    이미지 출처  https://medium.com/analytics-vidhya/multiple-linear-regression-an-intuitive-approach-f874f7a6a7f9  https://towardsdatascience.com/an-intuitive-explanation-of-gradient-descent-83adf68c9c33  https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html  https://observablehq.com/@petulla/l1-l2l_1-l_2l1-l2-norm-geometric-interpretation"
  },
  
  {
    "title": "Support Vector Machine",
    "url": "/posts/SVM/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Classification",
    "date": "2024-01-07 00:00:00 +0900",
    





    
    "snippet": "Support Vector Machine      정의 : 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘            용어의 이해              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장...",
    "content": "Support Vector Machine      정의 : 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘            용어의 이해              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장 가까이 위치한 벡터      마진(Margin) : 인접한 두 범주의 서포트 벡터를 지나는 평행한 두 직선 사이의 유클리드 거리      결정 함수 도출정의      초평면 정의\\[\\overrightarrow{w}^{T}\\overrightarrow{x}+b=0\\]          $\\overrightarrow{x}$ : 초평면 위에 위치한 벡터      $\\overrightarrow{w}$ : 초평면의 법선 벡터      $b$ : 편향으로서 세로축 절편            범주 정의\\[y_{i} = \\begin{cases}  +1,\\;if\\;\\overrightarrow{x}_{i} \\in X^{+}\\\\  -1,\\;if\\;\\overrightarrow{x}_{i} \\in X^{-}  \\end{cases}\\]        서포트 벡터 정의                  편의상 관측치 벡터 $\\overrightarrow{x}_{\\forall}$ 와 초평면 사이 거리 절대값은 최소 $1$ 이라고 하자                    좌측 서포트 벡터 $\\overrightarrow{x}^{+}$ : 범주 $X^{+}$ 에서 초평면에 가장 가까이 위치한 벡터\\[\\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=+1\\]                    우측 서포트 벡터 $\\overrightarrow{x}^{-}$ : 범주 $X^{-}$ 에서 초평면에 가장 가까이 위치한 벡터\\[\\overrightarrow{w}^{T}\\overrightarrow{x}^{-}+b=-1\\]            마진 도출      우측 서포트 벡터 $\\overrightarrow{x}^{-}$ 에 대하여 방향 $\\overrightarrow{w}$ 으로 크기 $margin$ 만큼 이동하면 좌측 서포트 벡터 $\\overrightarrow{x}^{+}$ 에 안착한다고 하자\\[\\overrightarrow{x}^{+} = \\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w}\\]        $\\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=1$ 을 다음과 같이 재정의할 수 있음\\[\\begin{aligned}  \\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=1\\\\  \\overrightarrow{w}^{T}(\\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w})+b=1\\\\  \\overrightarrow{w}^{T}\\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w}^{T}\\overrightarrow{w} + b = 1\\\\  (\\overrightarrow{w}^{T}\\overrightarrow{x}^{-} + b) + margin \\cdot \\overrightarrow{w}^{T}\\overrightarrow{w} = 1\\\\  -1 + margin \\cdot ||w||^2 = 1  \\end{aligned}\\]        따라서 마진을 다음과 같이 도출할 수 있음\\[margin = \\frac{2}{||w||^2}\\]  마진 최대화  최적화 문제 정의                  목적 함수\\[\\max{\\frac{2}{||w||^2}}  \\Rightarrow \\min{\\frac{1}{2}||w||^2}\\]                    제약 조건\\[y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1\\]                  라그랑주 함수 도출\\[\\begin{aligned}  L(w,b,\\lambda)&amp;=\\frac{1}{2}||w||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}  \\end{aligned}\\]          $\\lambda_{i}\\ge0$ : 라그랑주 승수        KKT 조건 하 라그랑주 듀얼 함수로 변환                  목적 함수\\[\\begin{aligned}  g(\\lambda) &amp;= \\inf_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}{\\min_{w,b}{L(w,b,\\lambda)}}  \\end{aligned}\\]                    제약 조건 ($\\because$ Complementary Slackness, KKT)\\[\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}=0\\]                  서포트 벡터 : \\(y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b = 1\\))          그 외 벡터 : \\(\\lambda_{i \\notin SV}=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\notin SV}+b &gt; 1\\))                          라그랑주 듀얼 함수 풀이                  $\\overrightarrow{w}$, $b$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial L(w,b,\\lambda)}{\\partial w}  &amp;= \\overrightarrow{w} - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  &amp;= 0\\\\  \\therefore \\overrightarrow{w}^{*}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\\\\\  \\frac{\\partial L(w,b,\\lambda)}{\\partial b}  &amp;= 0 - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}\\\\  &amp;= 0\\\\  \\therefore \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}   &amp;= 0  \\end{aligned}\\]                    편미분한 결과를 라그랑주 듀얼 함수에 대입\\[\\begin{aligned}  \\frac{1}{2}||w^{*}||^2  &amp;= \\frac{1}{2}\\overrightarrow{w}^{*}\\cdot\\overrightarrow{w}^{*}\\\\  &amp;= \\frac{1}{2}\\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}} \\cdot \\sum_{j=1}^{n}{\\lambda_{j}y_{j}\\overrightarrow{x}_{j}}\\\\  &amp;= \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}^{T}\\overrightarrow{x}_{j}}\\\\\\\\  \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}} + b\\sum_{i=1}^{n}{\\lambda_{i}y_{i}} - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}(\\sum_{j=1}^{n}\\lambda_{j}y_{j}\\overrightarrow{x}_{j})\\overrightarrow{x}_{i}} + b \\cdot 0 - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\  &amp;= \\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}\\overrightarrow{x}_{j}} - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\\\\\  \\therefore g(\\lambda)  &amp;= \\inf_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}\\min_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}{L(\\lambda)}\\\\  &amp;= \\max_{\\lambda}{\\left[\\frac{1}{2}||w^{*}||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}\\right]}\\\\  &amp;= \\max_{\\lambda}{\\left[\\sum_{i=1}^{n}{\\lambda_{i}} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}^{T}\\overrightarrow{x}_{j}}\\right]}  \\end{aligned}\\]            서포트 벡터 도출      마진을 최대화하는 법선 벡터 $\\overrightarrow{w}^{*}$\\[\\overrightarrow{w}^{*}  = \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\]    마진을 최대화하는 편향 $b^{*}$          라그랑주 듀얼 함수의 제약 조건 ($\\because$ Complementary Slackness, KKT)                  서포트 벡터 : \\(y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b = 1\\))          그 외 벡터 : $\\lambda_{i \\notin SV}=0$ ($\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\notin SV}+b &gt; 1$)                            마진을 구함에 있어 그 외 벡터는 필요하지 않음\\[y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\]                    따라서 마진을 최대화하는 서포트 벡터의 편향 $b^{*}_{SV}$ 을 다음과 같이 도출할 수 있음\\[\\begin{aligned}  b^{*}  &amp;= y_{i \\in SV} - \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}{\\left[y_{i} - \\overrightarrow{w}^{T}\\overrightarrow{x}_{i}\\right]}\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}{\\left[y_{i} - \\left(\\sum_{j \\in SV}{\\lambda_{j}y_{j}\\overrightarrow{x}_{j}}\\right)\\overrightarrow{x}_{i}\\right]}\\;(\\because \\overrightarrow{w}^{*}=\\sum_{i}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}})\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}  \\end{aligned}\\]                  마진을 최대화하는 서포트 벡터 $\\overrightarrow{x}_{SV} \\in SV$\\[\\begin{aligned}  SV   &amp;= \\{\\overrightarrow{x}_{SV}|\\overrightarrow{w}^{*} \\cdot \\overrightarrow{x}_{SV} + b^{*}=|1|\\}\\\\  &amp;= \\left\\{ \\overrightarrow{x}_{SV}|\\left(\\sum_{i=1}^{n}{\\lambda_{i}^{*}y_{i}\\overrightarrow{x}_{i}}\\right) \\cdot \\overrightarrow{x}_{SV} + \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}=|1| \\right\\}  \\end{aligned}\\]  요약\\[\\begin{aligned}y_{q}&amp;= \\begin{cases}+1,\\;if\\;f(\\overrightarrow{q}) &gt; 0 \\\\-1,\\;if\\;f(\\overrightarrow{q}) &lt; 0 \\\\\\end{cases}\\\\\\\\f(\\overrightarrow{q})&amp;= \\overrightarrow{w}^{*} \\cdot \\overrightarrow{q} + b^{*}\\\\&amp;= \\left(\\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\right) \\cdot \\overrightarrow{q} + \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}\\end{aligned}\\]  $\\overrightarrow{q}$ : 신규 관측치 벡터  $y_{q}$ : $\\overrightarrow{q}$ 의 범주  $f(\\overrightarrow{q})$ : 결정 함수로서 초평면 $\\overrightarrow{w}^{T}\\overrightarrow{x}+b=0$ 과 벡터의 사영 거리소프트 마진      하드 마진(Hard Margin)의 문제점 : 이상 관측치가 존재하는 경우 마진을 최대화하는 초평면을 탐색하기 어려움            소프트 마진(Soft Margin)의 해결책 : 마진 위반 $\\xi$ 를 허용하여 일부 이상 관측치를 배제했을 때 마진을 최대화하는 초평면을 탐색함              마진 위반(Margin Violation; $\\xi$) : 초평면 근방에서 발생 가능한 소수의 이상 관측치에 대한 오류로서, 해당 관측치로부터 서포트 벡터를 지나고 초평면과 평행한 직선까지의 유클리드 거리      마진 위반 $\\xi$ 를 고려하는 최적화 문제 정의      하드 마진의 최적화 문제\\[\\begin{aligned}  &amp;\\min{\\frac{1}{2}||w||^2}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1  \\end{aligned}\\]        소프트 마진의 최적화 문제\\[\\begin{aligned}  &amp;\\min{\\left[\\frac{1}{2}{||w||^2}+C\\sum_{i=1}^{n}{\\xi_i}\\right]}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1-\\xi_i,\\\\  &amp;\\xi_i \\ge 0  \\end{aligned}\\]                  $\\xi_{i}$ : 관측치 벡터 $\\overrightarrow{x}_{i}$ 에 대한 마진 위반                    $C$ : 마진 위반에 대한 규제 강도                    라그랑주 승수법에 기초한 풀이      라그랑주 함수 도출\\[\\begin{aligned}  L(w,b,\\lambda,\\xi,\\mu)  = &amp;\\left[\\frac{1}{2}||w||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\{y_{i}(\\overrightarrow{w}^{T}+b)-(1-\\xi_{i})\\}}\\right]\\\\  &amp;+ \\left[C\\sum_{i=1}^{n}{\\xi_{i}}-\\sum_{i=1}^{b}{\\mu_{i}\\xi_{i}}\\right]  \\end{aligned}\\]          $\\lambda \\ge 0$ : 제약 조건 $y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}+b) \\ge 1-\\xi_{i}$ 에 대한 라그랑주 승수      $\\mu \\ge 0$ : 제약 조건 $\\xi_{i} \\ge 0$ 에 대한 라그랑주 승수            KKT 조건 하 라그랑주 듀얼 함수 도출\\[\\begin{aligned}  g(\\lambda,\\mu)  &amp;= \\inf_{w,b,\\xi}{L(w,b,\\lambda,\\xi,\\mu)}\\\\  &amp;= \\max_{\\lambda,\\mu}{\\min_{w,b,\\xi}{L(w,b,\\lambda,\\xi,\\mu)}}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;\\lambda_{i}\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}+b)-(1-\\xi_{i})\\}=0,\\\\  &amp;\\mu_{i}\\xi_{i}=0  \\end{aligned}\\]        $\\overrightarrow{w}$,$b$,$\\xi$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial w}  &amp;= \\overrightarrow{w} - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  &amp;= 0\\\\\\\\  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial b}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}\\\\  &amp;= 0\\\\\\\\  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial \\xi}  &amp;= C-\\lambda_{i}-\\mu_{i}\\\\  &amp;= 0\\\\\\\\  \\therefore \\overrightarrow{w}^{*}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}},\\\\  \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}  &amp;= 0,\\\\  \\mu_{i}  &amp;= C - \\lambda_{i}  \\end{aligned}\\]        위 결과를 라그랑주 듀얼 함수에 대입하여 $\\overrightarrow{w}^{}$,$b^{}$ 도출\\[\\begin{aligned}  \\overrightarrow{w}^{*}  &amp;= \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  b^{*}  &amp;= \\sum_{i \\in SV}{\\sum_{j \\in SV}{\\left[y_{i}-\\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}}  \\end{aligned}\\]  Kernel Trick      정의 : 선형으로는 구분하기 어려운 저차원 공간상의 데이터 세트를, 적절한 결정 경계를 찾을 수 있는 고차원 공간으로 매핑하는 기법      머서의 정리(Mercer’s Theorem)  저차원 공간 $L$ 에서 고차원 공간 $H$ 로 관측치들을 매핑하는 커널함수 $K$ 는 $L$ 에서 표현된 관측치들 간 유클리드 거리와 $H$ 에서 표현된 관측치들 간 유클리드 거리를 보존함      임의의 관측치 $X_a, X_b$ 에 대하여, $2$ 차원 공간에서 해당 관측치를 나타내는 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1\\\\a_2\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1\\\\b_2\\end{pmatrix}  \\end{aligned}\\]        $\\overrightarrow{a}, \\overrightarrow{b}$ 을 $3$ 차원상의 벡터 $\\Phi(\\overrightarrow{a}),\\Phi(\\overrightarrow{b})$ 로 매핑하는 커널함수 $K(\\overrightarrow{a}, \\overrightarrow{b})$ 는 다음의 조건을 만족함\\[\\begin{aligned}  K(\\overrightarrow{a}, \\overrightarrow{b})  &amp;= (\\overrightarrow{a}^T \\overrightarrow{b})^2 \\\\  &amp;= a_1^2b_1^2 + 2(a_1b_1a_2b_2) + a_2^2b_2^2 \\\\  &amp;= (a_1^2, \\sqrt{2}a_1a_2, a_2^2) \\cdot (b_1^2, \\sqrt{2}b_1b_2, b_2^2) \\\\  &amp;= \\Phi(\\overrightarrow{a}) \\cdot \\Phi(\\overrightarrow{b})  \\end{aligned}\\]  커널함수의 종류      Linear\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\overrightarrow{a}^T \\overrightarrow{b}\\]        Polynomial\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = (\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)^d\\]        Radial Basis Function(RBF)\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\exp(-\\gamma ||\\overrightarrow{a}- \\overrightarrow{b}||^2)\\]        Hyperbolic Tangent\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\tanh(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)\\]  SVR      초평면\\[\\begin{aligned}  f(\\overrightarrow{x}_{i})  &amp;= \\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b  \\end{aligned}\\]        차이점 : 제약 조건                      판별 분석 : 마진 범위 이내에 관측치 벡터가 존재하지 않음\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1 + \\xi_{i},\\\\  &amp;\\xi_{i} \\ge 0  \\end{aligned}\\]                    회귀 분석 : 마진 범위 이내에 모든 관측치 벡터가 존재함\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp;-(\\varepsilon + \\xi_{i}) \\le f(\\overrightarrow{x}_{i}) - y_{i} \\le \\varepsilon + \\eta_{i},\\\\  &amp;\\xi_{i},\\eta_{i} \\ge 0  \\end{aligned}\\]                  SVR 최적화 문제\\[\\overrightarrow{\\hat{w}},\\hat{b},\\hat{\\xi}_{i},\\hat{\\eta}_{i}  =\\argmin_{\\overrightarrow{w},b,\\xi,\\eta}{\\left[\\frac{1}{2}||w||^{2}+C\\sum_{i=1}^{n}{(\\xi_{i}+\\eta_{i})}\\right]}\\\\  \\begin{aligned}  \\\\ \\text{s.t.} \\quad  &amp; \\varepsilon + \\xi_{i} + f(\\overrightarrow{x}) - y_{i} \\ge 0,\\\\  &amp; \\varepsilon + \\eta_{i} - f(\\overrightarrow{x}) + y_{i} \\ge 0,\\\\  &amp; \\xi_{i}, \\eta_{i} \\ge 0  \\end{aligned}\\]  sklearn.svm.SVCfrom sklearn.svm import SVCGeneral HyperParameter  random_state(default : None)Model HyperParameter  decision_function_shape(default : 'ovr') : 다항 분류 시 결정 경계 탐색 방법          'ovo' : One VS One(일대일 구분 결정 경계 탐색)      'ovr' : One VS Rest(일대다 구분 결정 경계 탐색)      Soft Margin      C(default : 1.0) : 마진 위반에 대한 규제 강도    gamma(default : 'scale') : 결정 경계를 얼마나 유연하게 그을 것인가          'auto' : $\\displaystyle\\frac{1}{n(features)}$      'scale' : $\\displaystyle\\frac{1}{n(features) \\times X.var()}$      float type        tol(default : 0.001) : 허용 오차Kernel Trick  kernel(default : 'rbf') : 커널함수 설정          'linear' : $\\overrightarrow{a}^T \\overrightarrow{b}$      'poly' : $(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)^d$      'rbf' : $\\tanh(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)$            degree(default : 3) : 다항식 커널함수의 차수 $d$ 설정    coef0(default : 0.0) : 다항식 커널함수의 상수항 $r$ 설정To Prevent Overfitting  max_iter(default : -1) : 결정 경계 탐색 최대 횟수To Prevent Underfitting  class_weight(default : None) : 가중할 범주와 그 값          'balanced'      dictionary type      이미지 출처  https://velog.io/@shlee0125  https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927"
  },
  
  {
    "title": "kNN",
    "url": "/posts/kNN/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Classification",
    "date": "2024-01-06 00:00:00 +0900",
    





    
    "snippet": "k-Nearest Neighbors      정의 : 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]        한계점          검색 비용 문제                  관측치 갯수만큼 거리를 계산해야 함         ...",
    "content": "k-Nearest Neighbors      정의 : 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]        한계점          검색 비용 문제                  관측치 갯수만큼 거리를 계산해야 함                    거리 측정 함수 설정 문제                  분석가가 문제에 적합한 함수를 판단해야 함          고차원으로 갈수록 거리 개념이 무의미해짐          범주형 변수의 경우 각 범주 간 거리를 정의해야 함                    기하 거리 측정 방법맨해튼 거리 측정법      맨해튼 거리(Manhattan Distance; L1) : 두 점 사이의 엣지(Edge) 갯수          $\\overrightarrow{i_{1}}, \\overrightarrow{i_{2}}, \\cdots, \\overrightarrow{i_{n}}$ 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리를 합산한 값            계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 맨해튼 거리 $d_{L1}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= || \\overrightarrow{a} - \\overrightarrow{b} ||_{L1} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n} |a_i - b_i|  \\end{aligned}\\]            유클리드 거리 측정법  유클리드 거리(Euclidean Distance; L2) : 두 점 사이의 직선 거리          $\\overrightarrow{i_{1}}, \\overrightarrow{i_{2}}, \\cdots, \\overrightarrow{i_{n}}$ 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리의 제곱을 합산한 후 제곱근한 값        계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 유클리드 거리 $d_{L2}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= || \\overrightarrow{a} - \\overrightarrow{b} ||_{L2} \\\\  &amp;= \\sqrt{\\displaystyle\\sum_{i=1}^{n} (a_i - b_i)^2}  \\end{aligned}\\]            코사인 거리 측정법      코사인 거리(Cosine Distance; $\\cos$) : 임의의 두 점에 대하여, 원점과 각 점을 잇는 직선의 사이각 $\\theta$ 의 코사인 값        계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 코사인 거리 $d_{cos}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= \\cos{\\theta}\\\\  &amp;= \\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{||a||\\cdot||b||}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{a_{i}b_{i}}}{\\sqrt{\\sum_{i=1}^{n}{a_{i}^{2}}} \\cdot \\sqrt{\\sum_{i=1}^{n}{b_{i}^{2}}}}\\;(a_{i^{\\forall}}\\in\\overrightarrow{a},b_{i^{\\forall}}\\in\\overrightarrow{b})  \\end{aligned}\\]            하버사인 거리 측정법      하버사인 거리(Haversine Distance; $\\text{hav}$) : 구 표면상에 존재하는 두 지점에 대하여, 위도($\\varphi$), 경도($\\lambda$) 및 호 중심각($\\Theta$)을 활용하여 측정한 호의 길이        계산 방법                  반지름이 $r$, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta  \\end{aligned}\\]                    점 $A$,$B$ 의 위도가 $\\varphi_{A}$,$\\varphi_{B}$, 경도가 $\\lambda_{A}$,$\\lambda_{B}$ 이고, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호의 길이 $\\text{hav}{\\Theta}$ 는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\text{hav}(\\varphi_{B}-\\varphi_{A})  + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})  \\end{aligned}\\]                    $\\sin$, $\\cos$, $\\text{hav}$ 의 관계는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\sin^{2}{\\frac{\\Theta}{2}}\\\\  &amp;= \\frac{1-\\cos{\\Theta}}{2}  \\end{aligned}\\]                    따라서 반지름, 경도, 위도가 주어졌을 때 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta\\\\  &amp;= r \\cdot \\text{archav}(\\text{hav}{\\Theta})\\\\  &amp;= 2r \\cdot \\arcsin(\\sqrt{\\text{hav}{\\Theta}})\\\\  &amp;= 2r \\cdot \\arcsin\\left(\\sqrt{\\text{hav}(\\varphi_{B}-\\varphi_{A}) + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})}\\right)  \\end{aligned}\\]            sklearn.neighbors.KNeighborsClassifierfrom sklearn.neighbors import KNeighborsClassifierGeneral HyperParameter  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter      n_neighbors(default : 5) : 참조할 근접 벡터의 갯수    metric(default : 'minkowski') : 거리 측정 방법          'l1', 'manhattan' or 'cityblock' : 맨해튼 거리 측정법      'l2' or 'euclidean' : 유클리드 거리 측정법      'cosine' : 코사인 거리 측정법      'haversine' : 하버사인 거리 측정법      callable            p(default : 2) : metric 의 아규먼트가 'minkowski' 인 경우 추가 설정\\[minkowski=\\left(\\displaystyle\\sum_{i=1}^{n}{|x_i-y_i|^p}\\right)^{\\frac{1}{p}}\\]          1 : 맨해튼 거리 측정법      2 : 유클리드 거리 측정법        weights(default : 'uniform') : 근접 벡터에 대하여 가중치 부여 방법 설정          None      'uniform' : 근접 벡터에 대하여 동등한 가중치를 부여함      'distance' : 근접 벡터에 대하여 거리에 따른 가중치를 부여함      callable      이미지 출처  https://076923.github.io/posts/Python-opencv-43/"
  },
  
  {
    "title": "Naive Bayes",
    "url": "/posts/Naive_Bayes/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Classification",
    "date": "2024-01-05 00:00:00 +0900",
    





    
    "snippet": "Naive Bayes      정의 : 조건부 확률에 기초하여 관측치의 범주를 판별하는 알고리즘        조건부 확률의 이해\\[\\begin{aligned}P(B|A)&amp;= \\frac{P(A,B)}{P(A)}\\end{aligned}\\]                                                      $$P(B   ...",
    "content": "Naive Bayes      정의 : 조건부 확률에 기초하여 관측치의 범주를 판별하는 알고리즘        조건부 확률의 이해\\[\\begin{aligned}P(B|A)&amp;= \\frac{P(A,B)}{P(A)}\\end{aligned}\\]                                                      $$P(B              A)\\(: 사건\\)A\\(가 발생한 상태에서 사건\\)B$$ 가 발생할 확률                                          \\(P(A,B)\\) : 사건 \\(A\\), \\(B\\) 가 공동으로 발생할 확률      \\(P(A)\\) : 사건 \\(A\\) 가 발생할 확률      \\(P(B)\\) : 사건 \\(B\\) 가 발생할 확률            한계점 : Class Conditional Independent Assumption                  Class Conditional Independent Assumption : 범주 내에서 특정 특성의 존재 또는 부재가 다른 특성의 존재 또는 부재와 독립적이라는 가정\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n}|Y)  &amp;= P(X_{1}|Y) \\times P(X_{2}|Y) \\times \\cdots \\times P(X_{n}|Y)  \\end{aligned}\\]            결정 함수 도출      문제 정의\\[\\begin{aligned}  \\hat{Y}  &amp;= f(\\overrightarrow{x})\\\\  &amp;= \\text{arg} \\max_{Y}{P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          관측치 벡터 \\(\\overrightarrow{x}\\) 의 범주 \\(\\hat{Y}\\) 는 \\(\\overrightarrow{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 로 주어졌을 때, 범주 \\(Y\\) 가 \\(i=1,2,\\cdots\\) 일 확률이 최대인 \\(i\\) 임            베이즈 정리에 의해 다음이 성립함\\[\\begin{aligned}  &amp;P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]                                                      $$P(Y=i              X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\(: 관측치 벡터\\)\\overrightarrow{x}=(x_{1},x_{2},\\cdots,x_{n})\\(가 주어졌을 때, 해당 관측치의 범주\\)Y$$ 가 $i$ 일 확률                                                                                      $$P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}              Y=i)\\(: 범주\\)Y=i\\(가 주어졌을 때, 관측치 벡터\\)\\overrightarrow{x}\\(가\\)(x_{1},x_{2},\\cdots,x_{n})$$ 일 확률                                          \\(P(Y=i)\\) : 범주 \\(Y\\) 가 \\(i\\) 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 벡터 \\(\\overrightarrow{x}$ 가 $(x_{1},x_{2},\\cdots,x_{n})\\) 일 확률            클래스 조건부 독립 가정 하 다변량 조건부 확률을 단변량 조건부 확률로 변환할 수 있음\\[\\begin{aligned}  &amp;P(X_{1},X_{2},\\cdots,X_{n}|Y)\\\\  &amp;= P(X_{1}|Y) \\times P(X_{2}|Y) \\times \\cdots \\times P(X_{n}|Y)  \\end{aligned}\\]        따라서 관측치 벡터 \\(\\overrightarrow{x}\\) 의 범주 \\(Y\\) 가 \\(i\\) 일 확률은 다음과 같음\\[\\begin{aligned}  &amp;P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{\\sum_{j}P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=j)}\\\\  &amp;= \\frac{\\prod_{k=1}^{n}{P(X_{k}=x_{k}|Y=i)} \\cdot P(Y=i)}{\\sum_{j}{\\prod_{k=1}^{n}{P(X_{k}=x_{k}|Y=j)}}}  \\end{aligned}\\]  라플라스 평활화      라플라스 평활화(Laplace Smoothing) : 훈련 데이터 세트에 존재하지 않는 사례 \\(\\overrightarrow{x}_{k}\\) 에 대한 확률을 \\(0\\) 으로 부여하는 것을 방지하기 위한 기법        계산 방법\\[P(\\overrightarrow{x}_{k}|Y)  = \\frac{\\text{count}(\\overrightarrow{x}_{k},Y)+\\alpha}{\\text{count}(Y)+2\\alpha}\\]                                                      $$P(\\overrightarrow{x}_{k}              Y)\\(: 관측치 벡터\\)\\overrightarrow{x}_{k}\\(가 범주\\)Y$$ 에 속할 조건부 확률                                          \\(\\text{count}(\\overrightarrow{x}_{k},Y)\\) : 관측치 벡터 \\(\\overrightarrow{x}_{k}\\) 와 범주 \\(Y\\) 의 동시 출현 빈도      \\(\\text{count}(Y)\\) : 범주 \\(Y\\) 의 출현 빈도      \\(\\alpha\\) : 라플라스 평활화 강도      sklearn.naive_bayes.MultinomialNBfrom sklearn.naive_bayes import MultinomialNBLaplace Smoothing  alpha(default : 1.0) : 라플라스 평활화 강도  force_alpha(default : False) : alpha 하한선을 \\(1e-10\\) 으로 강제할지 여부Learn Class Prior Probabilities  fit_prior(default : True) : 클래스 사전 확률 학습 여부          True : 훈련 데이터 세트의 클래스 사전 확률을 학습함      False : 클래스 사전 확률을 균등하게 부여함        class_prior(default : None) : 클래스 사전 확률 강제 지정"
  },
  
  {
    "title": "Decision Tree",
    "url": "/posts/Decision_Tree/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Classification",
    "date": "2024-01-04 00:00:00 +0900",
    





    
    "snippet": "Decision Tree      정의 : 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘            구조              루트 노드(Root Node) : 깊이가 0인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건 ...",
    "content": "Decision Tree      정의 : 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘            구조              루트 노드(Root Node) : 깊이가 0인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건      리프 노드(Leaf Node) : 하위 노드가 존재하지 않는 노드로서 최종 범주      서브트리(Subtree) : 어떠한 규칙 노드를 루트 노드로 가지는 하위 트리로서 판별 규칙 집합의 부분집합      재귀적 분기(Recursive Partitioning)      정의 : 판별 규칙을 기준으로 상위 노드를 분할하여 순도가 높은 하위 노드를 생성하는 반복적인 과정                  판별 규칙 : 어떤 분기에서 하나의 설명변수를 사용하여 생성한 분할 조건                            순도(Purity) : 어떤 노드에 속한 관측치들이 동일한 범주에 속하는 정도                          순도를 정확히 측정하기 어려우므로 그 대리변수로서 불순도(Impurity)를 사용함                    판별 규칙      어떤 노드에 대하여, 설명변수 $X_{i} \\ge x_{i}$ 를 기준으로 해당 노드를 분할한다고 하자\\[y=\\begin{cases}  \\begin{aligned}  N_{left},\\;&amp;if\\;X_{i} \\ge x_{i}\\\\  N_{right},\\;&amp;if\\;X_{i} &lt; x_{i}\\\\  \\end{aligned}  \\end{cases}\\]        판별 규칙 $X_{i} \\ge x_{i}$ 의 비용 $J(X_{i} \\ge x_{i})$ 는 다음과 같음\\[\\begin{aligned}  J(X_{i} \\ge x_{i})  &amp;= \\frac{m_{left}}{m}I_{left} + \\frac{m_{right}}{m}I_{right}  \\end{aligned}\\]          $m$ : 결정 노드에 속한 관측치 갯수      $m_{left}$ : 좌측 하위 노드로 분기한 관측치 갯수      $I_{left}$ : 좌측 하위 노드의 불순도      $m_{right}$ : 우측 하위 노드로 분기한 관측치 갯수      $I_{right}$ : 우측 하위 노드의 불순도            설명변수 $X_{i}$ 기준 분할 시 최적의 분기점 $\\hat{x}_{i}$ 는 다음과 같음\\[\\hat{x}_{i}  =\\text{arg} \\min_{x_{i}}{J(X_{i} \\ge x_{i})}\\]        특정 노드를 분할하는 최적의 설명변수 $\\hat{X}_{i}$ 는 다음과 같음\\[\\hat{X}_{i}  = \\text{arg} \\min_{X_{i}}{\\left\\{\\min{J(X_{1})},\\min{J(X_{2})},\\cdots,\\min{J(X_{n})}\\right\\}}\\]  불순도      지니 지수(Gini Index) : 불순도를 경제적 불평등 개념에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율            엔트로피 지수(Entropy Index) : 불순도를 정보 획득의 불확실성 개념에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= -\\sum_{i=1}^{c}{\\left[p_{i} \\cdot \\log_{2}{p_{i}}\\right]}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율      가지치기(Pruning)      정의 : 자세하게 구분된 영역을 통합함으로써 과적합을 방지하는 기법    절차          Full Tree 생성      모든 노드에 대하여 비용 복잡도 지수 계산      비용 복잡도 지수가 가장 낮은 노드에 대하여 가지치기 수행      2~3 단계를 반복하며 최적의 $\\alpha$ 탐색      최적의 $\\alpha$ 하 Tree 도출            비용 복잡도 지수(Cost-Complexity)\\[\\begin{aligned}  R_{\\alpha}(T)  &amp;= L(T) + \\alpha \\cdot |\\text{leaf}(T)|\\\\  L(T)  &amp;= \\sum_{m=1}^{|\\text{leaf}(T)|}{\\sum_{\\overrightarrow{x}_{i} \\in R_{m}}{(y_{i}-\\hat{y}_{i})^2}}  \\end{aligned}\\]          $T$ : 타깃 노드를 루트 노드로 하는 서브트리      $\\text{leaf}(T)$ : $T$ 의 리프 노드 집합      $R_{m} \\in \\text{leaf}(T)$ : $T$ 의 $m$ 번째 리프 노드      \\(\\overrightarrow{x}_{i} \\in R_{m}\\) : \\(R_{m}\\) 에 속한 \\(i\\) 번째 관측치 벡터      $y_{i}$ : $\\overrightarrow{x}_{i}$ 의 실제값      \\(\\hat{y}_{i}\\) : \\(\\overrightarrow{x}_{i}\\) 의 예측값      $\\alpha$ : 가지치기 강도      $L(T)$ : $T$ 의 훈련 관측치에 대한 예측 손실      $R_{\\alpha}(T)$ : 타깃 노드의 비용 복잡도 지수      DTR      재귀적 분기\\[\\begin{aligned}  \\hat{X}_{i}  &amp;= \\text{arg} \\min_{X_{i}}{\\{J(X_{1},\\hat{x}_{1}),J(X_{2},\\hat{x}_{2}),\\cdots,J(X_{n},\\hat{x}_{n})\\}}\\\\  \\hat{x}_{i}  &amp;= \\text{arg} \\min_{x_{i}}{J(X_{i},x_{i})}\\\\  J(X_{i},x_{i})  &amp;= \\frac{m_{left}}{m}L_{left}+\\frac{m_{right}}{m}L_{right}  \\end{aligned}\\]        차이점 : 손실 함수                      판별 분석 : 불순도(Impurity)를 최소화하도록 분기\\[\\begin{aligned}  L_{gini}(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]                    회귀 분석 : 오차(Error)를 최소화하도록 분기\\[\\begin{aligned}  L_{MSE}(N_{k})  &amp;= \\sum_{i=1}^{m}{(y_{i}-\\hat{y}_{i})^2}  \\end{aligned}\\]            sklearn.tree.DecisionTreeClassifierfrom sklearn.tree import DecisionTreeClassifierGeneral HyperParameter  random_state(default : None)Model HyperParameter  max_features(default : None) : 규칙 설계 시 고려할 설명변수 갯수          'sqrt' : $\\sqrt{n}$      'log2' : $\\log_2{n}$      None : $n$      Recursive Partitioning  criterion(default : 'gini') : 균일도 측정 방법          'gini' : 지니지수      'entropy' : 엔트로피지수      Pruning  ccp_alpha(default : 0)To Prevent Overfitting  max_depth(default : None) : 트리 최대 깊이  max_leaf_nodes(default : None) : 리프 노드의 최대 갯수  min_samples_split(default : 2) : 하위 노드로 가지를 뻗기 위해 필요한 최소한의 관측치 갯수  min_impurity_decrease(default : 0) : 하위 노드로 가지를 뻗기 위해 필요한 최소한의 불순도 개선 정도  min_samples_leaf(default : 1) : 리프 노드의 관측치 최소 갯수To Prevent Underfitting  class_weight(default : None) : 가중할 범주와 그 값          'balanced'      dictionary type      "
  },
  
  {
    "title": "Supervised Model Selection",
    "url": "/posts/Supervised_Model_Selection/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Supervised Learning, Metric, Cross Validation",
    "date": "2024-01-03 00:00:00 +0900",
    





    
    "snippet": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitiv...",
    "content": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitive) 중 잘못 예측한(False) 항목  FN(False Negative) : 부정으로 예측한 것(Negative) 중 잘못 예측한(False) 항목Sensitive to Threshold      정확도(Accuracy) : 전체 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP + TN}{TP + TN + FP + FN}\\]        민감도(Sensitivity) 혹은 재현율(Recall) : 실제 긍정인 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP}{TP + FN}\\]        특이도(Specificity) : 실제 부정인 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TN}{TN + FP}\\]        정밀도(Precision) : 긍정으로 예측한 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP}{TP + FP}\\]        F1-Score : 재현율과 정밀도의 조화 평균\\[2 \\times \\frac{precision \\times recall}{precision + recall}\\]          재현율 : 제1종 오류(참을 거짓으로 예측하는 오류; FN)를 강조하는 지표      정밀도 : 제2종 오류(거짓을 참으로 예측하는 오류; FP)를 강조하는 지표      AUROC : Robust to Threshold      AUROC                      ROC Curve(Receiver Operating Characteristic Curve) : FPR 값에 따른 TPR의 변화 추이를 나타낸 곡선                    AUROC(Area Under ROC) : ROC Curve 아래 면적                  이상적 분류기(Ideal Classifier) : 1          무작위 분류기(Random Classifier) : 0.5                          개념 설명                  FNR(False Negative Rate) : 실제 긍정인 관측치(TP+FN) 대비 잘못 예측한 관측치(FN) 비율\\[\\begin{aligned}  FNR  &amp;=\\frac{FN}{TP+FN}  \\end{aligned}\\]                    TPR(True Positive Rate) : 실제 긍정인 관측치(TP+FN) 대비 옳게 예측한 관측치(TP) 비율\\[\\begin{aligned}  TPR  &amp;=\\frac{TP}{TP+FN}\\\\  &amp;= 1-FNR  \\end{aligned}\\]                    FPR(False Possitive Rate) : 실제 부정인 관측치(TN+FP) 대비 잘못 예측한 관측치(FP) 비율\\[\\begin{aligned}  FPR  &amp;=\\frac{FP}{TN+FP}  \\end{aligned}\\]                    TNR(True Negative Rate) : 실제 부정인 관측치(TN+FP) 대비 옳게 예측한 관측치(TN) 비율\\[\\begin{aligned}  TNR  &amp;=\\frac{TN}{TN+FP}\\\\  &amp;= 1-FPR  \\end{aligned}\\]            Regression Metrics      Average Error(AE)\\[AE=\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}-\\hat{y}_{i}}\\]          정의 : 오차의 합계      한계점 : 오차의 방향에 따른 크기 상쇄 가능성            Mean Squared Error(MSE) : 오차 자승의 평균\\[MSE = \\frac{1}{n}\\sum_{i=1}^{n}{(y_{i}-\\hat{y}_{i})^2}\\]        Root Mean Squared Error(RMSE) : 오차 자승의 평균의 자승근\\[RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{(y_{i}-\\hat{y}_{i})^2}}\\]        Mean Absolute Error(MAE) : 오차 절대값의 평균\\[MAE = \\frac{1}{n}\\sum_{i=1}^{n}{|y_{i}-\\hat{y}_{i}|}\\]        Mean Absolute Percentage Error(MAPE) : 실제값 대비 오차 비율 절대값의 평균\\[MAPE = \\frac{1}{n}\\sum_{i=1}^{n}|\\frac{y_{i}-\\hat{y}_{i}}{y_{i}}|\\]  Split일반화의 문제  모델링 목적 : 일반화          일반화(Generalization) : 모델이 훈련 관측치에서 학습한 패턴을 사용하여 이전에 보지 못한 관측치에 대하여 예측하는 것            문제점 : 과대적합 현상              과대적합(Overfitting) : 모델이 일반적이지 않은, 즉 훈련 관측치에서만 포착되는 노이즈나 이상치까지 학습하여 신규 관측치에 대해서는 제대로 기능하지 못하는 상태      과소적합(Underfitting) : 모델이 훈련 관측치에서 나타나는 일반적인 패턴을 충분히 학습하지 못하여 관측치의 다양성과 복잡성을 잡아내지 못하는 상태            해결 방법 : $E_{gen}$ 최소화                      Training Error : Training Data Set 에 대한 오차\\[E_{trn} = \\sum^{N_{trn}}_{i=1}{L(y_{i},\\hat{y}_{i})}\\]                    Generalization Error : Unseen Data Set 에 대한 오차\\[E_{gen}=\\int{L(y_{i},\\hat{y}_{i})}\\]            모수의 추정  $E_{gen}$ 측정 상의 문제점          Unseen Data Set 자체에 대해서 알 수 없으므로 이상적인 개념임      해당 모수를 추정하기 위하여 추정량 $E_{val}$, $E_{tst}$ 를 제시함            Split Seen Data Set              Training : 모델 훈련 시 사용하는 표본으로서, 해당 표본으로부터 $E_{val}$ 을 추정함      Validation : 모델 간 성능 비교 시 사용하는 표본으로서, 해당 표본으로부터 $E_{tst}$ 를 추정함      Test : 최종 선택된 모델 성능 측정 시 사용하는 표본으로서, 해당 표본로부터 $E_{gen}$ 를 추정함      Cross Validation      교차 검증(Cross Validation)              정의 : 표본을 여러 세트로 나누어 모델을 여러 번 학습하고 평가함으로써 모델의 일반화 성능을 측정하는 절차      필요성 : Training 에서 Test 를 분리한 상태에서 Validation 을 재차 분리하기에는 학습에 사용할 표본 크기가 충분하지 않음            LOOCV(Leave-One-Out Cross Validation)              $n$ 개의 표본을 $n-1$ 개의 training 과 $1$ 개의 validation 으로 나누어 $n$ 번 학습하는 방식            k-Fold Cross Validation              $n$ 개의 표본을 $k$ 개의 데이터 세트로 나누고, $k-1$ 개는 training 으로, $1$ 개는 validation 으로 구분하여 $k$ 번 학습하는 방식      "
  },
  
  {
    "title": "Data Preprocessing",
    "url": "/posts/Data_Preprocessing/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "Feature Engineering",
    "date": "2024-01-02 00:00:00 +0900",
    





    
    "snippet": "Data Preprocessing      정의 : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정    필요성 : 분석에 완벽하게 적합한 데이터를 얻는 것은 불가능함          호환성 문제                  데이터 불일치          데이터 중복                    데이터 수집 문제       ...",
    "content": "Data Preprocessing      정의 : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정    필요성 : 분석에 완벽하게 적합한 데이터를 얻는 것은 불가능함          호환성 문제                  데이터 불일치          데이터 중복                    데이터 수집 문제                  센서와 데이터베이스 간 통신 문제          센서 자체 문제          샘플링 기반 데이터 수집 정책                      데이터 품질에 영향을 끼치는 인자          Nosie : 데이터 측정 시 무작위로 발생하여 오류를 발생시키는 문제      Outlier : 대부분의 데이터와 다른 특성을 보이거나 특정 속성의 값이 유별난 데이터      Artifact : 어떤 요인으로 인해 반복적으로 발생하는 왜곡이나 오류      Precision : 동일한 결과물을 반복적으로 측정하였을 때 각 측정값 사이의 일관성 문제      Bias : 측정 장비에 포함된 시스템 상 문제      Accuacy : 측정 장비의 한계로 정확하지 않은 수를 측정함에 따라 발생하는 문제      Inconsistent Value : 데이터 불일치 문제      Duplicate : 데이터 중복 문제        절차                  Data Integration : 동일한 단위, 양식으로 데이터를 결합하는 절차            Data Cleansing : 낮은 품질의 데이터를 활용할 수 있도록 하는 절차                  중복값 제거          결측치 처리          이상치 처리                    Data Transformation : 데이터 형식 및 구조를 학습에 적합하도록 변환하는 절차                  표준화(Standardization)          정규화(Normalization)                    Data Reduction : 고차원 데이터를 저차원 데이터로 변환하는 절차      Data Cleansing결측치 처리  결측치 종류          완전 무작위 결측(Missing Completely At Random; MCAR) : 데이터가 어떤 패턴이나 규칙 없이 누락되는 경우      무작위 결측(Missing At Random; MAR) : 데이터의 누락이 다른 변수에 종속된 경우      비무작위 결측(Missing Not At Random; MNAR) : 결측치가 어떤 규칙 또는 패턴을 따라 발생하는 경우        결측치 처리 권장 사항          10% 미만 : 제거 또는 대체      10~20% : 최빈값, 평균, 중앙값 등으로 대체      20% 이상 : model-based method      이상치 처리      이상치의 정의 : 관측된 데이터의 범위에서 지나치게 벗어나 값이 매우 크거나 작은 값        이상치의 탐지 : Turkey Fence 기법    \\[\\begin{aligned}  Outliers  &amp;=\\{X|X &lt; X_{lower} \\; or \\; X &gt; X_{upper}\\}  \\end{aligned}\\]          하한값($X_{lower}$) : $Q_1-IQR \\times 1.5$      상한값($X_{upper}$) : $Q_3+IQR \\times 1.5$      사분위 범위(InterQuartile Range; IQR) : $Q_3 - Q_1$      Data Transformationz-Score 정규화from sklearn.preprocessing import StandardScaler      정의 : 값의 분포를 평균이 0, 분산이 1인 형태로 변환함\\[X_{scaled}=\\frac{X_{origin}-E(X)}{\\sigma}\\]        기능 : 정규 분포화  (이상치) 강건 정규화from sklearn.preprocessing import RobustScaler      정의 : 평균과 분산 대신 중앙값과 사분위 범위를 활용함\\[X_{scaled}=\\frac{X_{origin}-median}{IQR}\\]        기능 : 이상치 영향력 최소화  최대-최소 정규화from sklearn.preprocessing import MinMaxScaler      정의 : 값의 분포를 특정 범위로 확대 혹은 축소함\\[X_{scaled}=\\frac{X_{origin}-X_{min}}{X_{max}-X_{min}}\\]        기능 : 척도 통일  "
  },
  
  {
    "title": "What? Data Science",
    "url": "/posts/Data_Science/",
    "categories": "Artificial Intelligence, Machine Learning",
    "tags": "",
    "date": "2024-01-01 00:00:00 +0900",
    





    
    "snippet": "Data-Driven Decision Making데이터 기반 의사결정  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend     ...",
    "content": "Data-Driven Decision Making데이터 기반 의사결정  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend          Ability to Drill Down to the Root-cause      Ability to Isolate All Confounding Information        Predictive : Forcasts What Might Happned          Business Have Remained Fairly Consistent Over Time      Historical Patterns Being Used to Predict Specific Outcomes Using Algorithms      Decisions are Automated Using Algorithms and Tech.        Prescriptive : What Do I Need to Do?          Recommends Action Based On The Forecast      Applying Advanced Analytical Techs to Make Specific Recommendatons      데이터 기반 문제 해결 과정      문제 정의          어떤 문제를 해결할 것인가?이를 위해 필요한 데이터는 무엇인가?            데이터 획득          어떻게 데이터를 수집할 것인가?            데이터 탐색          데이터 전처리탐색적 자료 분석            모델링          문제에 맞는 기계학습 알고리즘 선택모델 구축            배포          제품 배포 및 시스템 유지 보수      Data Science데이터 과학의 이해      정의          정형, 비정형의 다양한 데이터로부터 지식 및 시사점을 도출하는 데 과학적 방법론을 동원하는 융합 분야(출처 : 위키백과)            주요 개념                  빅데이터(Bigdata)                  통상적으로 사용되는 데이터 수집, 관리, 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터(출처 : 위키백과)                          Volume(Data Quantity)          Variety(Data Types)          Velocity(Data Speed)          Value(Data Impact)                            데이터 마이닝(Data Mining)                  대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 짜임을 분석하여 가치 있는 정보를 빼내는 과정(출처 : 위키백과)                            기계학습(Machine Learning)                  기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야(출처 : 위키백과)                            인공지능(Artificial Intelligence; AI)                  인간의 학습, 추론, 지각 능력을 인공적으로 구현하려는 컴퓨터 과학의 세부 분야(출처 : 위키백과)                    기계학습의 분류  지도학습(Supervised Learning)                  정의 : 정답 세트가 존재하는 데이터를 활용하는 학습 방법                    분류                  판별 분석(Classificaiton) : 범주형 값을 가지는 종속변수를 예측하는 방법론          회귀 분석(Regression) : 수치형 값을 가지는 종속변수를 예측하는 방법론                      비지도학습(Unsupervised Learning)                  정의 : 정답 세트가 존재하지 않는 데이터를 활용하는 학습 방법                    분류                  군집화(Clustering) : 유사한 개체들의 집단을 만든 후 새 개체가 어떤 집단과 유사한지 예측하는 방법론          차원축소(Dimension Reduction) : 고차원 데이터를 저차원 데이터로 변환하는 방법론                    Scikit-Learn Library      API 사용 방법          적절한 알고리즘 클래스 불러오기      인터페이스의 하이퍼 파라미터를 적절한 값으로 설정하여 인스턴스 생성      데이터 세트를 문제지(Feature)와 정답지(Traget)로 배치      fit() 을 통해 인스턴스를 학습용 데이터 세트로 훈련      predict() 을 통해 훈련된 인스턴스에 평가용 데이터 세트를 적용하여 성능 평가      모듈      알고리즘                            모듈          설명          예시                                      sklearn.tree          결정 트리 알고리즘 제공          Decision Tree 등                          sklearn.neighbors          최근접 이웃 알고리즘 제공          K-NN 등                          sklearn.svm          서포트 벡터 머신 알고리즘 제공                                     sklearn.naive_bayes          나이브 베이즈 알고리즘 제공          가우시안 NB, 다항 분포 NB 등                          sklearn.cluster          클러스터링 알고리즘 제공          K-Means, 계층형 클러스터링, DBSCAN 등                          sklearn.linear_model          회귀분석 알고리즘 제공          선형 회귀, 확률적 경사하강 회귀(SGD), 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등                          sklearn.decomposition          차원 축소 알고리즘 제공          PCA, NMF, Truncated SVD 등                          sklearn.ensemble          앙상블 알고리즘 제공          Random Forest, AdaBoost, GradientBoost 등                          전처리                            모듈          설명          예시                                      sklearn.preprocessing          데이터 전처리 기능 제공          인코더, 스케일러 등                          sklearn.feature_selection          특성(feature)을 선택할 수 있는 기능 제공                                     sklearn.feature_extraction          특성(feature)을 추출할 수 있는 기능 제공                                     sklearn.pipeline          특성 처리, 학습, 예측을 묶어서 실행할 수 있는 기능 제공                                     검증 및 성능 평가 지표                            모듈          설명          예시                                      sklearn.model_selection          교차 검증, 최적 하이퍼파라미터 추출 API 제공          GridSearch 등                          sklearn.metrics          성능 평가 지표 제공          Accuracy, Precision, Recall, ROC-AUC, RMSE 등                    내장 데이터 세트sklearn.datasets      내장 데이터 형식                            이름          설명                                      DESCR          자료에 대한 설명                          data          설명 변수                          target          반응 변수                          feature_names          설명 변수 이름 리스트                          target_names          반응 변수 이름 리스트                          내장 데이터 세트 목록                            데이터 로드 함수          데이터          참고                                      load_boston          보스턴 집값          내장 데이터                          load_diabetes          당뇨병                                     load_linnerud          linnerud                                     load_iris          붓꽃                                     load_digits          필기 숫자(digit) 이미지                                     load_wine          포도주(wine) 등급                                     load_breast_cancer          유방암 진단                                     fetch_california_housing          캘리포니아 집값          인터넷 다운로드                          fetch_covtype          토지조사                                     fetch_20newsgroups          뉴스 그룹 텍스트                                     fetch_olivetti_faces          얼굴 이미지                                     fetch_lfw_people          유명인 얼굴                                     fetch_lfw_pairs          유명인 얼굴                                     fetch_rcv1          로이터 뉴스 말뭉치                                     fetch_kddcup99          Kddcup 99 Tcp dump                                     make_regression          회귀분석용          가상 데이터                          make_classification          분류용                                     make_blobs          클러스터링용                               "
  }
  
]

